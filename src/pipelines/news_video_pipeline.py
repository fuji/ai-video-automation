"""
„Éã„É•„Éº„ÇπÂãïÁîª„Éë„Ç§„Éó„É©„Ç§„É≥

Ë®ò‰∫ã„Åã„ÇâË§áÊï∞„Ç∑„Éº„É≥„ÅÆ„Éã„É•„Éº„ÇπÂãïÁîª„ÇíËá™ÂãïÁîüÊàê
"""

import os
import subprocess
import json
from pathlib import Path
from dataclasses import dataclass, field
from typing import Optional
from datetime import datetime

from PIL import Image, ImageDraw, ImageFont
from rich.console import Console
from google import genai

import fal_client
import httpx
import time

from src.generators.image_generator import FluxImageGenerator, PollinationsImageGenerator
from src.generators.remotion_generator import RemotionGenerator, SceneConfig
from src.config import config, get_daily_output_dirs
from src.generators.edge_tts_generator import EdgeTTSGenerator  # ÁÑ°ÊñôTTS
from src.editors.news_graphics import NewsGraphicsCompositor
from src.editors.intro_outro import IntroOutroGenerator, IntroOutroConfig
from src.audio.bgm_manager import BGMManager, MoodType

console = Console()


@dataclass
class Scene:
    """„Ç∑„Éº„É≥ÊÉÖÂ†±"""
    index: int
    description: str  # „Ç∑„Éº„É≥„ÅÆË™¨Êòé
    image_prompt: str  # FluxÁî®„Éó„É≠„É≥„Éó„Éà
    video_prompt: str  # LumaÁî®„Éó„É≠„É≥„Éó„Éà
    subtitle: str  # „Åì„ÅÆ„Ç∑„Éº„É≥„ÅÆÂ≠óÂπï
    image_path: Optional[str] = None
    video_path: Optional[str] = None
    image_group: Optional[int] = None  # ÁîªÂÉè„Ç∞„É´„Éº„ÉóÁï™Âè∑Ôºà1-4Ôºâ


@dataclass
class NewsVideoResult:
    """„Éë„Ç§„Éó„É©„Ç§„É≥ÁµêÊûú"""
    success: bool
    video_path: Optional[str] = None
    scenes: list[Scene] = field(default_factory=list)
    audio_path: Optional[str] = None
    duration_seconds: float = 0.0
    error_message: Optional[str] = None


class NewsVideoPipeline:
    """„Éã„É•„Éº„ÇπÂãïÁîªÁîüÊàê„Éë„Ç§„Éó„É©„Ç§„É≥"""
    
    def __init__(
        self,
        channel_name: str = "FJ News 24",
        num_scenes: int = 10,  # 10„Ç∑„Éº„É≥„ÅßÁ¥Ñ60-90Áßí„ÅÆÂãïÁîª
        scene_duration: float = 5.0,
        use_remotion: bool = True,  # Remotion „Çí‰Ωø„ÅÜÔºàÁÑ°ÊñôÔºâ„Åã Luma „Çí‰Ωø„ÅÜÔºàÊúâÊñôÔºâ
        image_provider: str = "pollinations",  # "pollinations" (ÁÑ°Êñô) or "flux" (ÊúâÊñô)
        discord_webhook_url: Optional[str] = None,  # DiscordÈÄöÁü•Áî®Webhook URL
    ):
        self.channel_name = channel_name
        self.num_scenes = num_scenes
        self.scene_duration = scene_duration
        self.use_remotion = use_remotion
        self.image_provider = image_provider
        self.discord_webhook_url = discord_webhook_url or os.environ.get("DISCORD_WEBHOOK_URL")
        
        # Êó•‰ªò„Éô„Éº„Çπ„ÅÆÂá∫Âäõ„Éá„Ç£„É¨„ÇØ„Éà„É™
        self.dirs = get_daily_output_dirs()
        
        # ÁîªÂÉè„Ç∏„Çß„Éç„É¨„Éº„Çø„ÉºÂàùÊúüÂåñÔºà„Éó„É≠„Éê„Ç§„ÉÄ„ÉºÈÅ∏ÊäûÔºâ
        if image_provider == "pollinations":
            self.image_gen = PollinationsImageGenerator()
            console.print(f"[cyan]üñºÔ∏è ÁîªÂÉèÁîüÊàê: Pollinations.aiÔºàÁÑ°ÊñôÔºâ[/cyan]")
        else:
            self.image_gen = FluxImageGenerator()
            console.print(f"[cyan]üñºÔ∏è ÁîªÂÉèÁîüÊàê: Flux via fal.aiÔºàÊúâÊñôÔºâ[/cyan]")
        
        self.narration_gen = EdgeTTSGenerator()  # ÁÑ°ÊñôTTS (Edge TTS)
        self.compositor = NewsGraphicsCompositor(channel_name=channel_name)
        self.bgm_manager = BGMManager()  # BGMÁÆ°ÁêÜ
        self.intro_outro_gen = IntroOutroGenerator(IntroOutroConfig(
            channel_name=channel_name,
            channel_tagline="‰∏ñÁïå„ÅÆ„Åä„ÇÇ„Åó„Çç„Éã„É•„Éº„Çπ",
        ))
        
        # Remotion „Ç∏„Çß„Éç„É¨„Éº„Çø„ÉºÔºàÁÑ°Êñô„É¢„Éº„Ç∑„Éß„É≥„Ç∞„É©„Éï„Ç£„ÉÉ„ÇØ„ÇπÔºâ
        if use_remotion:
            self.remotion_gen = RemotionGenerator()
            console.print(f"[cyan]üé¨ Remotion „É¢„Éº„ÉâÔºàÁÑ°ÊñôÔºâ[/cyan]")
        else:
            self.remotion_gen = None
        
        # Gemini for scene analysis
        self.gemini_client = genai.Client(api_key=config.gemini.api_key)
        
        # FAL API key for Luma (Remotion‰Ωø„Çè„Å™„ÅÑÂ†¥Âêà)
        if not use_remotion:
            os.environ["FAL_KEY"] = config.fal.api_key
        
        console.print(f"[green]NewsVideoPipeline initialized[/green]")
        console.print(f"  Output: {self.dirs['root']}")
        console.print(f"  Channel: {channel_name}")
        console.print(f"  Scenes: {num_scenes} x {scene_duration}s = {num_scenes * scene_duration}s")
        console.print(f"  Mode: {'Remotion (ÁÑ°Êñô)' if use_remotion else 'Luma (ÊúâÊñô)'}")
    
    def generate_scenes_data(
        self,
        article_text: str,
        headline: str,
        num_scenes: int = 10,
    ) -> dict:
        """Ë®ò‰∫ã„Åã„Çâ„Ç∑„Éº„É≥ÊßãÊàê„Éá„Éº„Çø„ÇíÁîüÊàêÔºà„É¶„Éº„É¢„Ç¢‰ªò„Åç„ÄÅÈï∑„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥Ôºâ
        
        Returns:
            dict: run() „Å´Ê∏°„Åõ„ÇãÂΩ¢Âºè {headline, sub_headline, scenes_data, closing_text, ...}
        """
        
        # ÂøÉÁêÜÂ≠¶ÁöÑ„ÉÜ„ÇØ„Éã„ÉÉ„ÇØ„Çí„É©„É≥„ÉÄ„É†„Å´ÈÅ∏Êäû
        import random
        psych_techniques = [
            "„ÉÑ„Ç°„Ç§„Ç¨„É´„Éã„ÇØÂäπÊûú: „ÄåÁ∂ö„Åç„ÅØ...„Äç„Äå„Åù„ÅÆÁµêÊûú...„Äç„ÅßÊ¨°„Å∏„ÅÆÊúüÂæÖ„ÇíÁÖΩ„Çã",
            "Á§æ‰ºöÁöÑË®ºÊòé: „ÄåSNS„ÅßË©±È°å„Äç„Äå„Äá‰∏á‰∫∫„ÅåÈ©ö„ÅÑ„Åü„Äç„Å™„Å©„ÅÆÊï∞Â≠ó„ÇíÂÖ•„Çå„Çã",
            "Â∏åÂ∞ëÊÄß: „ÄåÁü•„Çã‰∫∫„ÅûÁü•„Çã„Äç„Äå1%„ÅÆ‰∫∫„Åó„ÅãÁü•„Çâ„Å™„ÅÑ„Äç„Å™„Å©ÁâπÂà•ÊÑü„ÇíÂá∫„Åô",
            "ÊÑüÊÉÖÁßªÂÖ•: ÁôªÂ†¥‰∫∫Áâ©„Å´ÂêçÂâç„Çí„Å§„Åë„Å¶Ë¶™ËøëÊÑü„ÇíÊåÅ„Åü„Åõ„Çã",
            "ÂØæÊØîÂäπÊûú: „ÄåÊôÆÈÄö„Å™„Çâ„Äá„Äá„ÄÅ„Åß„ÇÇ„Åì„ÅÆ‰∫∫„ÅØ‚ñ≥‚ñ≥„Äç„ÅßÈ©ö„Åç„ÇíÂº∑Ë™ø",
        ]
        selected_technique = random.choice(psych_techniques)
        
        # Ë¶ñË¶öÁöÑ„Éê„É™„Ç®„Éº„Ç∑„Éß„É≥„Çí„É©„É≥„ÉÄ„É†„Å´ÈÅ∏Êäû
        visual_variations = [
            "„ÇØ„É≠„Éº„Ç∫„Ç¢„ÉÉ„ÉóÔºàÈ°î„ÇÑÊâãÂÖÉ„ÅÆ„Éá„Ç£„ÉÜ„Éº„É´Ôºâ„ÇíÊÑèË≠ò„Åó„ÅüÊßãÂõ≥",
            "Â∫ÉËßí„ÉªÂºï„Åç„ÅÆÊßãÂõ≥„ÅßÂÖ®‰Ωì„ÅÆÁä∂Ê≥Å„ÇíË¶ã„Åõ„Çã",
            "„Éâ„É©„Éû„ÉÅ„ÉÉ„ÇØ„Å™ÂÖâ„Å®ÂΩ±„ÅÆ„Ç≥„É≥„Éà„É©„Çπ„Éà",
            "ÈÆÆ„ÇÑ„Åã„Å™Ëâ≤ÂΩ©„ÅßÂç∞Ë±°ÁöÑ„Å´",
            "„Éâ„Ç≠„É•„É°„É≥„Çø„É™„ÉºÈ¢®„ÅÆ„É™„Ç¢„É´„Å™Èõ∞Âõ≤Ê∞ó",
        ]
        selected_visual = random.choice(visual_variations)
        
        prompt = f"""„ÅÇ„Å™„Åü„ÅØ„Éê„Ç∫„ÇãÂãïÁîª„ÅÆ„Çπ„ÇØ„É™„Éó„Éà„É©„Ç§„Çø„Éº„Åß„Åô„ÄÇË¶ñËÅ¥ËÄÖ„ÅåÊúÄÂàù„ÅÆ3Áßí„ÅßÂºï„ÅçËæº„Åæ„Çå„ÄÅÊúÄÂæå„Åæ„ÅßË¶ã„Åü„Åè„Å™„ÇãÂãïÁîª„Çí‰Ωú„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

# Ë®ò‰∫ã
„Çø„Ç§„Éà„É´: {headline}
Êú¨Êñá: {article_text}

# üé£ „Éï„ÉÉ„ÇØÔºàË∂ÖÈáçË¶ÅÔºÅÔºâ
**ÁñëÂïèÂΩ¢„ÅßÂßã„ÇÅ„Çã**: Ë¶ñËÅ¥ËÄÖ„Å´„Äå„Åà„ÄÅ‰Ωï„Åù„ÇåÔºü„Äç„Å®ÊÄù„Çè„Åõ„Çã
‰æã:
- „Äå250kmÊ≠©„ÅÑ„Å¶Â∏∞„ÇãÁå´„ÄÅË¶ã„Åü„Åì„Å®„ÅÇ„ÇãÔºü„Äç
- „Äå2Ê≠≥ÂÖê„Åå‰∏ñÁïåË®òÈå≤„ÄÅ‰ø°„Åò„Çâ„Çå„ÇãÔºü„Äç
- „ÄåÁâ©‰πû„ÅÑ„ÅåÂÆü„ÅØÂÑÑ‰∏áÈï∑ËÄÖ„Å†„Å£„Åü„ÇâÔºü„Äç

# üîç „Éü„Çπ„ÉÜ„É™„ÉºÂûãÊßãÊàêÔºàË¨é‚ÜíÊâã„Åå„Åã„Çä‚ÜíÁ®ÆÊòé„Åã„ÅóÔºâ
- „Ç∑„Éº„É≥1-3ÔºàË¨é„ÅÆÊèêÁ§∫Ôºâ: Ë°ùÊíÉÁöÑ„Å™‰∫ãÂÆü„ÇÑÁñëÂïè„ÇíÊäï„Åí„Åã„Åë„Çã„ÄÇ„Äå„Å™„ÅúÔºü„Äç„Äå„Å©„ÅÜ„ÇÑ„Å£„Å¶Ôºü„Äç„ÇíË¶ñËÅ¥ËÄÖ„Å´ÊÄù„Çè„Åõ„Çã
- „Ç∑„Éº„É≥4-6ÔºàÊâã„Åå„Åã„ÇäÔºâ: ËÉåÊôØ„ÇÑÁä∂Ê≥Å„ÇíË™¨Êòé„ÄÇ„Åß„ÇÇÊ†∏ÂøÉ„ÅØ„Åæ„Å†Êòé„Åã„Åï„Å™„ÅÑ
- „Ç∑„Éº„É≥7-9ÔºàÂ±ïÈñãÔºâ: ‰∫ãÊÖã„ÅåÂãï„Åè„ÄÇÈ©ö„Åç„ÅÆÂ±ïÈñã„ÇÑËª¢ÊèõÁÇπ
- „Ç∑„Éº„É≥10-12ÔºàÁ®ÆÊòé„Åã„ÅóÔºâ: Á≠î„ÅàÂêà„Çè„Åõ„ÄÇÊÑüÂãï„ÇÑÈ©ö„Åç„ÅÆÁµêÊú´

# ‚è±Ô∏è „Éä„É¨„Éº„Ç∑„Éß„É≥„ÅÆÈï∑„ÅïÔºàÈáçË¶ÅÔºÅÔºâ
**ÂÖ®„Ç∑„Éº„É≥30-60ÊñáÂ≠ó**„ÅÆ„Åó„Å£„Åã„Çä„Åó„Åü„Éä„É¨„Éº„Ç∑„Éß„É≥„Åß„ÄÅË©±„ÅÆÊµÅ„Çå„ÅåÂàÜ„Åã„Çã„Çà„ÅÜ„Å´:
- Â∞éÂÖ•„Åß„ÇÇÁúÅÁï•„Åó„Åô„Åé„Å™„ÅÑ„ÄÇÁä∂Ê≥Å„Çí„Å°„ÇÉ„Çì„Å®Ë™¨Êòé„Åô„Çã
- Â±ïÈñã„Åß„ÅØË©≥Á¥∞„Çí‰ºù„Åà„Çã„ÄÇ„ÄåË™∞„Åå„Äç„Äå‰Ωï„Çí„Äç„Äå„Å©„ÅÜ„Åó„Åü„Äç„ÇíÊòéÁ¢∫„Å´
- „ÇØ„É©„Ç§„Éû„ÉÉ„ÇØ„Çπ„ÅØÊÑüÊÉÖ„ÇíËæº„ÇÅ„Å¶„ÄÅÂç∞Ë±°„Å´ÊÆã„Çã„Çà„ÅÜ„Å´
- Ë®ò‰∫ã„ÅÆÈáçË¶Å„Å™ÊÉÖÂ†±„ÇíÊºè„Çâ„Åï„Åö‰ºù„Åà„Çã

# üé≠ ‰ªäÂõû‰Ωø„ÅÜÂøÉÁêÜÂ≠¶„ÉÜ„ÇØ„Éã„ÉÉ„ÇØ
{selected_technique}

# üé® ‰ªäÂõû„ÅÆË¶ñË¶ö„Çπ„Çø„Ç§„É´
{selected_visual}

# „É¶„Éº„É¢„Ç¢„ÅÆÂÖ•„ÇåÊñπ
‚ùå Áå´„Åå250kmÊ≠©„ÅÑ„Å¶Â∏∞ÈÇÑ„Åó„Åæ„Åó„Åü„ÄÇÔºàË™¨ÊòéÁöÑ„Åß„Å§„Åæ„Çâ„Å™„ÅÑÔºâ
‚úÖ „Ç∞„Éº„Ç∞„É´„Éû„ÉÉ„Éó„Å™„Åó„ÄÅ„Çπ„Éû„Éõ„Å™„Åó„ÄÅ250km„ÄÇÁå´„ÅÆ„Éä„Éì„ÄÅÊúÄÂº∑„Åô„Åé„Å™„ÅÑÔºüÔºà„ÉÑ„ÉÉ„Ç≥„Éü + ÁñëÂïèÂΩ¢Ôºâ

# üñºÔ∏è ÁîªÂÉè„ÅÆÊåáÁ§∫ÔºàË∂ÖÈáçË¶ÅÔºÅÔºâ
**ÂêÑ„Ç∑„Éº„É≥„Å´Âõ∫Êúâ„ÅÆ visual_description „ÇíÊõ∏„Åè**ÔºàËã±Ë™û„ÅßÔºâ
- 12„Ç∑„Éº„É≥ÂÖ®„Å¶Áï∞„Å™„ÇãÁîªÂÉè„ÇíÁîüÊàê„Åô„Çã
- „Éä„É¨„Éº„Ç∑„Éß„É≥„ÅÆÂÜÖÂÆπ„Å´Âêà„Å£„ÅüÂÖ∑‰ΩìÁöÑ„Å™„Ç∑„Éº„É≥„ÇíÊèèÂÜô
- {selected_visual} „ÅÆ„Çπ„Çø„Ç§„É´„ÇíÊÑèË≠ò
- „ÄåÂêå‰∏ä„Äç„ÇÑÁúÅÁï•„ÅØÁ¶ÅÊ≠¢ÔºÅÂøÖ„ÅöÂÖ∑‰ΩìÁöÑ„Å´Êõ∏„Åè

# Âá∫ÂäõÂΩ¢Âºè (JSON)
```json
{{
  "headline": "Áü≠„ÅÑ„Çø„Ç§„Éà„É´Ôºà15ÊñáÂ≠ó‰ª•ÂÜÖ„ÄÅ„Ç§„É≥„Éë„ÇØ„ÉàÈáçË¶ñÔºâ",
  "sub_headline": "„Çµ„Éñ„Çø„Ç§„Éà„É´Ôºà20ÊñáÂ≠ó‰ª•ÂÜÖÔºâ",
  "hook": "ÁñëÂïèÂΩ¢„ÅÆ„Éï„ÉÉ„ÇØÔºàË¶ñËÅ¥ËÄÖ„Å∏„ÅÆÂïè„ÅÑ„Åã„ÅëÔºâ",
  "mood": "emotional|funny|dramatic|informative",
  "scenes": [
    {{"visual_description": "„Ç∑„Éº„É≥1„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "Ë¨é„ÅÆÊèêÁ§∫„Éª„Éï„ÉÉ„ÇØÔºà30-50ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥2„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "Áä∂Ê≥ÅË™¨ÊòéÔºà30-50ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥3„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "ËÉåÊôØ„ÉªÂ∞éÂÖ•„ÅÆÁ∑†„ÇÅÔºà30-50ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥4„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "Ë©≥Á¥∞„Å™Â±ïÈñã1Ôºà30-60ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥5„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "Ë©≥Á¥∞„Å™Â±ïÈñã2Ôºà30-60ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥6„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "Ë©≥Á¥∞„Å™Â±ïÈñã3Ôºà30-60ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥7„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "„ÇØ„É©„Ç§„Éû„ÉÉ„ÇØ„ÇπÂâçÔºà30-60ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥8„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "„ÇØ„É©„Ç§„Éû„ÉÉ„ÇØ„ÇπÔºà40-60ÊñáÂ≠ó„ÄÅÊÑüÊÉÖËæº„ÇÅ„Å¶Ôºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥9„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "„ÇØ„É©„Ç§„Éû„ÉÉ„ÇØ„ÇπÂæåÔºà30-50ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥10„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "Á®ÆÊòé„Åã„Åó„ÉªËß£Ê±∫Ôºà30-60ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥11„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "ÂæåÊó•Ë´á„ÉªÁèæÂú®Ôºà30-50ÊñáÂ≠óÔºâ"}},
    {{"visual_description": "„Ç∑„Éº„É≥12„ÅÆÂÖ∑‰ΩìÁöÑ„Å™ÁîªÂÉèË™¨ÊòéÔºàËã±Ë™ûÔºâ", "narration": "Âç∞Ë±°ÁöÑ„Å™Á∑†„ÇÅÔºà30-50ÊñáÂ≠óÔºâ"}}
  ],
  "closing_text": "Âç∞Ë±°„Å´ÊÆã„ÇãÁ∑†„ÇÅÔºà20ÊñáÂ≠óÁ®ãÂ∫¶Ôºâ"
}}
```

**ÂøÖ„Åö12„Ç∑„Éº„É≥ÁîüÊàê„ÄÇÂêÑ„Ç∑„Éº„É≥„Å´Âõ∫Êúâ„ÅÆ visual_descriptionÔºàËã±Ë™ûÔºâ„Å®„Éä„É¨„Éº„Ç∑„Éß„É≥Ôºà30-60ÊñáÂ≠óÔºâ„ÇíÊõ∏„ÅèÔºÅ**"""

        console.print(f"\n[cyan]üìù „Ç∑„Éº„É≥ÊßãÊàê„ÇíÁîüÊàê‰∏≠Ôºà{num_scenes}„Ç∑„Éº„É≥Ôºâ...[/cyan]")
        
        # „É™„Éà„É©„Ç§„É≠„Ç∏„ÉÉ„ÇØÔºàÊúÄÂ§ß3ÂõûÔºâ
        max_retries = 3
        last_error = None
        
        for attempt in range(max_retries):
            try:
                if attempt > 0:
                    console.print(f"[yellow]‚è≥ „É™„Éà„É©„Ç§ {attempt + 1}/{max_retries}Ôºà10ÁßíÂæÖÊ©üÔºâ...[/yellow]")
                    import time
                    time.sleep(10)
                
                response = self.gemini_client.models.generate_content(
                    model="gemini-2.0-flash",
                    contents=prompt,
                )
                
                # JSON„ÇíÊäΩÂá∫
                content = response.text
                json_start = content.find("{")
                json_end = content.rfind("}") + 1
                
                if json_start == -1 or json_end == 0:
                    raise ValueError("JSON not found in response")
                
                json_str = content[json_start:json_end]
                
                try:
                    data = json.loads(json_str)
                except json.JSONDecodeError as e:
                    console.print(f"[yellow]‚ö†Ô∏è JSON „Éë„Éº„Çπ„Ç®„É©„Éº„ÄÅ‰øÆÊ≠£„ÇíË©¶„Åø„Åæ„Åô...[/yellow]")
                    import re
                    # ‰ΩôÂàÜ„Å™„Ç´„É≥„Éû„ÇíÂâäÈô§„ÄÅÊîπË°å„ÇíÊï¥ÁêÜ
                    json_str = re.sub(r',\s*}', '}', json_str)
                    json_str = re.sub(r',\s*]', ']', json_str)
                    # ‰∏çÂÆåÂÖ®„Å™JSON„ÇíË£úÂÆå
                    if json_str.count('[') > json_str.count(']'):
                        json_str += ']' * (json_str.count('[') - json_str.count(']'))
                    if json_str.count('{') > json_str.count('}'):
                        json_str += '}' * (json_str.count('{') - json_str.count('}'))
                    data = json.loads(json_str)
                
                # „Ç∑„Éº„É≥Êï∞„ÉÅ„Çß„ÉÉ„ÇØ
                scenes = data.get('scenes', [])
                if len(scenes) < 6:
                    raise ValueError(f"„Ç∑„Éº„É≥Êï∞‰∏çË∂≥: {len(scenes)} < 6")
                
                # ÊàêÂäüÔºÅ
                break
                
            except Exception as e:
                last_error = e
                error_msg = str(e)
                if "429" in error_msg or "RESOURCE_EXHAUSTED" in error_msg:
                    console.print(f"[yellow]‚ö†Ô∏è Gemini API „É¨„Éº„ÉàÂà∂Èôê„ÄÅÂæÖÊ©ü‰∏≠...[/yellow]")
                elif "JSONDecodeError" in str(type(e)):
                    console.print(f"[yellow]‚ö†Ô∏è JSON „Éë„Éº„ÇπÂ§±Êïó„ÄÅ„É™„Éà„É©„Ç§„Åó„Åæ„Åô...[/yellow]")
                else:
                    console.print(f"[yellow]‚ö†Ô∏è „Ç®„É©„Éº: {error_msg[:100]}[/yellow]")
                
                if attempt == max_retries - 1:
                    console.print(f"[red]‚ùå {max_retries}Âõû„É™„Éà„É©„Ç§„Åó„Å¶„ÇÇÂ§±Êïó[/red]")
                    raise last_error
        
        console.print(f"  ‚úÖ {len(data.get('scenes', []))}„Ç∑„Éº„É≥ÁîüÊàê")
        console.print(f"  üì∞ {data.get('headline', headline)}")
        console.print(f"  üé≠ „É†„Éº„Éâ: {data.get('mood', 'neutral')}")
        
        return data
    
    def analyze_article(
        self,
        article_text: str,
        headline: str,
    ) -> list[Scene]:
        """Ë®ò‰∫ã„ÇíÂàÜÊûê„Åó„Å¶Ë§áÊï∞„Ç∑„Éº„É≥„Å´ÂàÜËß£ÔºàÂæåÊñπ‰∫íÊèõÁî®Ôºâ"""
        
        prompt = f"""‰ª•‰∏ã„ÅÆ„Éã„É•„Éº„ÇπË®ò‰∫ã„Çí{self.num_scenes}„Å§„ÅÆÊò†ÂÉèÁöÑ„Å™„Ç∑„Éº„É≥„Å´ÂàÜËß£„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ

# Ë®ò‰∫ã
„Çø„Ç§„Éà„É´: {headline}
Êú¨Êñá: {article_text}

# „Ç∑„Éº„É≥ÊßãÊàê„Ç¨„Ç§„ÉâÔºà{self.num_scenes}„Ç∑„Éº„É≥Ôºâ
1. „Ç™„Éº„Éó„Éã„É≥„Ç∞: Áä∂Ê≥ÅË®≠ÂÆö„ÄÅ‰∏ª‰∫∫ÂÖ¨„ÇÑËàûÂè∞„ÅÆÁ¥π‰ªã
2. Â±ïÈñã1: Âá∫Êù•‰∫ã„ÅÆÂßã„Åæ„Çä„ÄÅÂïèÈ°å„ÇÑÁä∂Ê≥Å„ÅÆÁô∫Áîü
3. Â±ïÈñã2: „ÇØ„É©„Ç§„Éû„ÉÉ„ÇØ„Çπ„ÄÅÊúÄ„ÇÇÂç∞Ë±°ÁöÑ„Å™Áû¨Èñì
4. „Ç®„É≥„Éá„Ç£„É≥„Ç∞: ÁµêÊú´„ÄÅÁèæÂú®„ÅÆÁä∂Ê≥Å„ÄÅ‰ΩôÈüª

# Âá∫ÂäõÂΩ¢Âºè (JSON)
ÂêÑ„Ç∑„Éº„É≥„Å´„Å§„ÅÑ„Å¶‰ª•‰∏ã„ÇíÁîüÊàê:
- description: „Ç∑„Éº„É≥„ÅÆË™¨ÊòéÔºàÊó•Êú¨Ë™û„ÄÅ1Êñá„ÅßÊò†ÂÉè„Çí„Ç§„É°„Éº„Ç∏„Åß„Åç„Çã„Çà„ÅÜ„Å´Ôºâ
- image_prompt: FluxÁîªÂÉèÁîüÊàêÁî®„Éó„É≠„É≥„Éó„ÉàÔºàËã±Ë™û„ÄÅ70Ë™û‰ª•ÂÜÖÔºâ
  * ÂÖ∑‰ΩìÁöÑ„Å™Ë¢´ÂÜô‰Ωì„ÄÅÂ†¥ÊâÄ„ÄÅÊôÇÈñìÂ∏Ø„ÄÅÈõ∞Âõ≤Ê∞ó„ÇíÂê´„ÇÅ„Çã
  * "photorealistic, cinematic lighting, 4K quality" „ÇíÂê´„ÇÅ„Çã
  * ‰∫∫Áâ©„Åå„ÅÑ„ÇãÂ†¥Âêà„ÅØË°®ÊÉÖ„ÇÑÂãï‰Ωú„ÇÇÊèèÂÜô
- video_prompt: LumaÂãïÁîªÁîüÊàêÁî®„Éó„É≠„É≥„Éó„ÉàÔºàËã±Ë™û„ÄÅ25Ë™û‰ª•ÂÜÖÔºâ
  * „Ç´„É°„É©„ÉØ„Éº„ÇØÔºàpan, zoom, dollyÁ≠âÔºâ„ÇíÊåáÂÆö
  * Âãï„Åç„ÅÆÊñπÂêë„Å®ÈÄüÂ∫¶„ÇíÂê´„ÇÅ„Çã
- subtitle: „Åì„ÅÆ„Ç∑„Éº„É≥„ÅÆÂ≠óÂπïÔºàÊó•Êú¨Ë™û„ÄÅ20-30ÊñáÂ≠ó„ÄÅÊÑüÊÉÖ„Åå‰ºù„Çè„Çã„Çà„ÅÜ„Å´Ôºâ

```json
{{
  "scenes": [
    {{
      "description": "...",
      "image_prompt": "...",
      "video_prompt": "...",
      "subtitle": "..."
    }}
  ]
}}
```"""

        console.print("\n[cyan]üìù Ë®ò‰∫ã„ÇíÂàÜÊûê‰∏≠...[/cyan]")
        
        response = self.gemini_client.models.generate_content(
            model="gemini-2.0-flash",
            contents=prompt,
        )
        
        # JSON„ÇíÊäΩÂá∫
        content = response.text
        json_start = content.find("{")
        json_end = content.rfind("}") + 1
        json_str = content[json_start:json_end]
        
        data = json.loads(json_str)
        
        scenes = []
        for i, scene_data in enumerate(data["scenes"]):
            scene = Scene(
                index=i,
                description=scene_data["description"],
                image_prompt=scene_data["image_prompt"],
                video_prompt=scene_data["video_prompt"],
                subtitle=scene_data["subtitle"],
                image_group=scene_data.get("image_group"),  # ÁîªÂÉè„Ç∞„É´„Éº„ÉóÁï™Âè∑
            )
            scenes.append(scene)
            console.print(f"  „Ç∑„Éº„É≥{i+1}: {scene.description}")
        
        return scenes
    
    def generate_scene_images(
        self,
        scenes: list[Scene],
        output_prefix: str,
    ) -> list[Scene]:
        """ÂêÑ„Ç∑„Éº„É≥„ÅÆÁîªÂÉè„ÇíÁîüÊàêÔºà1„Ç∑„Éº„É≥1ÁîªÂÉèÔºâ"""
        
        console.print("\n[cyan]üñºÔ∏è „Ç∑„Éº„É≥ÁîªÂÉè„ÇíÁîüÊàê‰∏≠Ôºà12ÊûöÔºâ...[/cyan]")
        
        for scene in scenes:
            # ÂêÑ„Ç∑„Éº„É≥„Å´Âõ∫Êúâ„ÅÆÁîªÂÉè„ÇíÁîüÊàê
            output_name = f"{output_prefix}_scene{scene.index + 1}"
            
            result = self.image_gen.generate(
                prompt=scene.image_prompt,
                output_name=output_name,
                image_size="landscape_16_9",  # Ê®™ÂãïÁîªÁî®
                output_dir=self.dirs["images"],
            )
            
            if result.success:
                scene.image_path = result.file_path
                console.print(f"  ‚úÖ „Ç∑„Éº„É≥{scene.index + 1}: {result.file_path}")
            else:
                console.print(f"  ‚ùå „Ç∑„Éº„É≥{scene.index + 1}: {result.error_message}")
        
        return scenes
    
    def generate_scene_videos_remotion(
        self,
        scenes: list[Scene],
        output_prefix: str,
        headline: str = "",
        sub_headline: str = "",
        is_breaking: bool = True,
        news_style: bool = True,
        mood: str = "exciting",
    ) -> list[Scene]:
        """Remotion „Åß„Éã„É•„Éº„ÇπÈ¢®ÂãïÁîª„ÇíÁîüÊàê
        
        Args:
            scenes: „Ç∑„Éº„É≥„É™„Çπ„ÉàÔºàimage_path „Åå„ÅÇ„Çå„Å∞„Åù„Çå„ÇíËÉåÊôØ„Å´‰ΩøÁî®Ôºâ
            output_prefix: Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ
            headline: „Éò„ÉÉ„Éâ„É©„Ç§„É≥ÔºàÊúÄÂàù„ÅÆ„Ç∑„Éº„É≥„ÅÆ„ÅøË°®Á§∫Ôºâ
            sub_headline: „Çµ„Éñ„Éò„ÉÉ„Éâ„É©„Ç§„É≥
            is_breaking: BREAKING NEWS Ë°®Á§∫
            news_style: „Éã„É•„Éº„ÇπÈ¢®„Çπ„Çø„Ç§„É´„Çí‰ΩøÁî®
            mood: „É†„Éº„ÉâÔºà„Ç∞„É©„Éá„Éº„Ç∑„Éß„É≥ËÉåÊôØ„ÅÆÂ†¥Âêà„Å´‰ΩøÁî®Ôºâ
        """
        
        console.print("\n[cyan]üé¨ „Ç∑„Éº„É≥ÂãïÁîª„ÇíÁîüÊàê‰∏≠ (Remotion)...[/cyan]")
        
        # „É†„Éº„Éâ„Å´Âü∫„Å•„ÅèËâ≤Ôºà„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÁî®Ôºâ
        mood_colors = {
            "exciting": ["#FF6B6B", "#FF8E53"],
            "heartwarming": ["#A8E6CF", "#DCEDC1"],
            "funny": ["#FFE66D", "#FFB347"],
            "shocking": ["#E94560", "#1A1A2E"],
            "informative": ["#4ECDC4", "#44A08D"],
        }
        
        # ÁîªÂÉè„Ç∞„É´„Éº„Éó„Åî„Å®„Å´„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥ÈÄ≤Êçó„ÇíË®àÁÆóÔºàv11ÊñπÂºèÔºâ
        # Âêå„ÅòÁîªÂÉè„Çí‰Ωø„ÅÜ„Ç∑„Éº„É≥„Åß„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥„ÅåÁ∂ôÁ∂ö„Åô„Çã
        image_groups = {}  # image_path -> list of scene indices
        image_group_numbers = {}  # image_path -> group number (1-based)
        group_counter = 1
        for scene in scenes:
            img = getattr(scene, 'image_path', None)
            if img:
                if img not in image_groups:
                    image_groups[img] = []
                    image_group_numbers[img] = group_counter
                    group_counter += 1
                image_groups[img].append(scene.index)
        
        # ÂêÑ„Ç∞„É´„Éº„Éó„ÅÆÂêàË®àÊôÇÈñì„ÇíË®àÁÆó
        group_durations = {}
        for img, indices in image_groups.items():
            total = sum(getattr(scenes[i], 'audio_duration', 5.0) or 5.0 for i in indices)
            group_durations[img] = total
        
        # ÂêÑ„Ç∑„Éº„É≥„ÅÆ„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥ÈñãÂßã/ÁµÇ‰∫Ü‰ΩçÁΩÆ„ÇíË®àÁÆó
        group_progress = {img: 0.0 for img in image_groups}
        scene_anim = {}  # scene.index -> (start, end)
        for scene in scenes:
            img = getattr(scene, 'image_path', None)
            if img and img in group_durations:
                total = group_durations[img]
                dur = getattr(scene, 'audio_duration', 5.0) or 5.0
                start = group_progress[img] / total if total > 0 else 0
                group_progress[img] += dur
                end = group_progress[img] / total if total > 0 else 1
                scene_anim[scene.index] = (start, end)
            else:
                scene_anim[scene.index] = (0.0, 1.0)
        
        for scene in scenes:
            output_path = str(self.dirs["videos"] / f"{output_prefix}_scene{scene.index + 1}.mp4")
            duration = getattr(scene, 'audio_duration', 5.0) or 5.0
            narration_text = getattr(scene, 'narration_text', scene.subtitle) or scene.description
            anim_start, anim_end = scene_anim.get(scene.index, (0.0, 1.0))
            
            # „Ç∑„Éº„É≥Áï™Âè∑„ÇíÂèñÂæóÔºàÂêÑ„Ç∑„Éº„É≥Âõ∫Êúâ„ÅÆÁîªÂÉèÔºâ
            img = getattr(scene, 'image_path', None)
            scene_num = scene.index + 1  # 1-based
            group_num = image_group_numbers.get(img, scene_num) if img else scene_num
            
            # ËÉåÊôØÁîªÂÉè„Åå„ÅÇ„Çå„Å∞„Éã„É•„Éº„ÇπÈ¢®„ÄÅ„Å™„Åë„Çå„Å∞„É¢„Éº„Ç∑„Éß„É≥„Ç∞„É©„Éï„Ç£„ÉÉ„ÇØ„Çπ
            if scene.image_path and news_style:
                # „Éã„É•„Éº„ÇπÈ¢®ÔºàËÉåÊôØÁîªÂÉè + „Ç™„Éº„Éê„Éº„É¨„Ç§Ôºâ
                # - „ÉÅ„É£„É≥„Éç„É´„É≠„Ç¥: ÂÖ®„Ç∑„Éº„É≥„ÅßË°®Á§∫
                # - „Éê„Éä„ÉºÔºàBREAKING + „Çø„Ç§„Éà„É´ + „Çµ„Éñ„Çø„Ç§„Éà„É´Ôºâ: ÂÖ®„Ç∑„Éº„É≥„ÅßË°®Á§∫
                # - Â≠óÂπï: ÂÖ®„Ç∑„Éº„É≥„ÅßË°®Á§∫
                result = self.remotion_gen.generate_news_scene(
                    scene_number=group_num,  # ÁîªÂÉè„Ç∞„É´„Éº„ÉóÁï™Âè∑„Åß„Ç¢„Éã„É°„Éº„Ç∑„Éß„É≥„Éë„Çø„Éº„É≥Ê±∫ÂÆö
                    duration=duration,
                    output_path=output_path,
                    background_image=scene.image_path,
                    subtitle=narration_text if narration_text else "",  # ÂÖ®ÊñáË°®Á§∫
                    headline=headline,  # ÂÖ®„Ç∑„Éº„É≥„ÅßË°®Á§∫
                    sub_headline=sub_headline,  # ÂÖ®„Ç∑„Éº„É≥„ÅßË°®Á§∫
                    channel_name=self.channel_name,
                    is_breaking=is_breaking,  # ÂÖ®„Ç∑„Éº„É≥„ÅßË°®Á§∫
                    show_overlay=True,  # ÂÖ®„Ç∑„Éº„É≥„ÅßË°®Á§∫
                    animation_start=anim_start,
                    animation_end=anim_end,
                )
            else:
                # „É¢„Éº„Ç∑„Éß„É≥„Ç∞„É©„Éï„Ç£„ÉÉ„ÇØ„ÇπÈ¢®Ôºà„Ç∞„É©„Éá„Éº„Ç∑„Éß„É≥ËÉåÊôØÔºâ
                base_colors = mood_colors.get(mood, mood_colors["exciting"])
                scene_config = SceneConfig(
                    scene_number=scene.index + 1,
                    duration=duration,
                    background_colors=base_colors,
                    elements=[
                        {
                            "type": "emoji",
                            "content": self._get_emoji_for_scene(scene.description),
                            "style": {"size": "xxl"},
                            "position": {"x": "center", "y": "center", "offsetY": -100},
                            "animation": {"enter": "bounce-in", "delay": 0},
                        },
                        {
                            "type": "text",
                            "content": narration_text[:40] if narration_text else scene.description[:40],
                            "style": {"size": "lg", "weight": "bold", "color": "#FFFFFF"},
                            "position": {"x": "center", "y": "center", "offsetY": 120},
                            "animation": {"enter": "fade-in-up", "delay": 0.5},
                        },
                    ],
                    subtitle=scene.subtitle[:50] if scene.subtitle else "",
                )
                result = self.remotion_gen.generate_scene(scene_config, output_path)
            
            if result.success:
                scene.video_path = output_path
                console.print(f"  ‚úÖ „Ç∑„Éº„É≥{scene.index + 1}: {output_path} ({result.duration_seconds:.1f}Áßí)")
            else:
                console.print(f"  ‚ùå „Ç∑„Éº„É≥{scene.index + 1}: {result.error_message}")
        
        return scenes
    
    def _get_emoji_for_scene(self, description: str) -> str:
        """„Ç∑„Éº„É≥Ë™¨Êòé„Åã„ÇâÈÅ©Âàá„Å™ÁµµÊñáÂ≠ó„ÇíÈÅ∏Êäû"""
        emoji_map = {
            "Áå´": "üê±", "Áä¨": "üê∂", "ÂãïÁâ©": "üêæ",
            "ÂÆ∂": "üè†", "Â∏∞": "üè†",
            "Ëªä": "üöó", "ÊóÖ": "üß≥", "ÈÅì": "üõ£Ô∏è",
            "Êµ∑": "üåä", "Â±±": "‚õ∞Ô∏è", "Á©∫": "‚òÅÔ∏è",
            "ÊÑõ": "‚ù§Ô∏è", "ÂøÉ": "üíï",
            "È©ö": "üò±", "Ë°ùÊíÉ": "üí•",
            "Á¨ë": "üòÇ", "Èù¢ÁôΩ": "ü§£",
            "Ê≥£": "üò≠", "ÊÑüÂãï": "ü•π",
            "ÁÅ´": "üî•", "ÁÜ±": "üî•",
            "Ëµ∞": "üèÉ", "Ê≠©": "üö∂",
            "È£ü": "üçΩÔ∏è", "ÊñôÁêÜ": "üë®‚Äçüç≥",
            "Âãù": "üèÜ", "ÂÑ™Âãù": "ü•á",
            "Áô∫Ë¶ã": "üîç", "Ë™øÊüª": "üî¨",
        }
        
        for keyword, emoji in emoji_map.items():
            if keyword in description:
                return emoji
        
        return "üì∞"  # „Éá„Éï„Ç©„É´„Éà
    
    def generate_scene_videos(
        self,
        scenes: list[Scene],
        output_prefix: str,
    ) -> list[Scene]:
        """ÂêÑ„Ç∑„Éº„É≥„ÅÆÂãïÁîª„ÇíÁîüÊàêÔºàLuma Dream Machine via fal.aiÔºâ"""
        
        console.print("\n[cyan]üé¨ „Ç∑„Éº„É≥ÂãïÁîª„ÇíÁîüÊàê‰∏≠ (Luma)...[/cyan]")
        
        for scene in scenes:
            if not scene.image_path:
                console.print(f"  ‚ö†Ô∏è „Ç∑„Éº„É≥{scene.index + 1}: ÁîªÂÉè„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
                continue
            
            output_path = str(self.dirs["videos"] / f"{output_prefix}_scene{scene.index + 1}.mp4")
            
            try:
                # ÁîªÂÉè„Çífal.ai„Å´„Ç¢„ÉÉ„Éó„É≠„Éº„Éâ
                image_url = fal_client.upload_file(scene.image_path)
                console.print(f"  üì§ „Ç∑„Éº„É≥{scene.index + 1}: ÁîªÂÉè„Ç¢„ÉÉ„Éó„É≠„Éº„ÉâÂÆå‰∫Ü")
                
                # Luma APIÂëº„Å≥Âá∫„Åó
                result = fal_client.subscribe(
                    "fal-ai/luma-dream-machine/image-to-video",
                    arguments={
                        "prompt": scene.video_prompt,
                        "image_url": image_url,
                        "aspect_ratio": "9:16",
                    },
                    with_logs=False,
                )
                
                # ÂãïÁîª„Çí„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ
                video_url = result["video"]["url"]
                response = httpx.get(video_url)
                with open(output_path, "wb") as f:
                    f.write(response.content)
                
                scene.video_path = output_path
                console.print(f"  ‚úÖ „Ç∑„Éº„É≥{scene.index + 1}: {output_path}")
                
            except Exception as e:
                console.print(f"  ‚ùå „Ç∑„Éº„É≥{scene.index + 1}: {str(e)}")
        
        return scenes
    
    def generate_narration(
        self,
        article_text: str,
        output_prefix: str,
        closing_text: str = "",
    ) -> tuple[str, float]:
        """Ë®ò‰∫ãÂÖ®Êñá„Åã„Çâ„Éä„É¨„Éº„Ç∑„Éß„É≥Èü≥Â£∞„ÇíÁîüÊàêÔºàÁ∑†„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥Âê´„ÇÄÔºâ
        
        Args:
            article_text: „Éä„É¨„Éº„Ç∑„Éß„É≥Áî®„ÅÆË®ò‰∫ã„ÉÜ„Ç≠„Çπ„Éà
            output_prefix: Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ
            closing_text: Á∑†„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥ÔºàÁúÅÁï•ÂèØÔºâ
        
        Returns:
            tuple: (audio_path, total_duration)
        """
        
        console.print("\n[cyan]üé§ „Éä„É¨„Éº„Ç∑„Éß„É≥ÁîüÊàê‰∏≠...[/cyan]")
        
        # Ë®ò‰∫ãÂÖ®Êñá„Çí„Éä„É¨„Éº„Ç∑„Éß„É≥„Å´‰ΩøÁî®
        full_text = article_text
        
        main_path = str(self.dirs["audio"] / f"{output_prefix}_narration.mp3")
        result = self.narration_gen.generate(text=full_text, output_path=main_path)
        
        if not result.success:
            console.print(f"  ‚ùå Èü≥Â£∞ÁîüÊàêÂ§±Êïó: {result.error_message}")
            return None, 0
        
        console.print(f"  ‚úÖ Êú¨Á∑®Èü≥Â£∞: {result.file_path} ({result.duration_seconds:.1f}Áßí)")
        
        # Á∑†„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥„Åå„ÅÇ„Çå„Å∞ËøΩÂä†
        if closing_text:
            console.print("  üé§ Á∑†„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥ÁîüÊàê‰∏≠...")
            closing_path = str(self.dirs["audio"] / f"{output_prefix}_closing.mp3")
            closing_result = self.narration_gen.generate(text=closing_text, output_path=closing_path)
            
            if closing_result.success:
                console.print(f"  ‚úÖ Á∑†„ÇÅÈü≥Â£∞: {closing_result.file_path} ({closing_result.duration_seconds:.1f}Áßí)")
                
                # Èü≥Â£∞„ÇíÁµêÂêà
                combined_path = str(self.dirs["audio"] / f"{output_prefix}_full.mp3")
                subprocess.run([
                    "ffmpeg", "-y",
                    "-i", main_path, "-i", closing_path,
                    "-filter_complex", "[0:a][1:a]concat=n=2:v=0:a=1[a]",
                    "-map", "[a]", combined_path
                ], capture_output=True)
                
                # ÁµêÂêàÂæå„ÅÆÈï∑„Åï„ÇíÂèñÂæó
                probe = subprocess.run(
                    ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                     "-of", "default=noprint_wrappers=1:nokey=1", combined_path],
                    capture_output=True, text=True
                )
                total_duration = float(probe.stdout.strip())
                console.print(f"  ‚úÖ ÂêàË®àÈü≥Â£∞: {total_duration:.1f}Áßí")
                return combined_path, total_duration
        
        return result.file_path, result.duration_seconds
    
    def compose_final_video(
        self,
        scenes: list[Scene],
        audio_path: str,
        audio_duration: float,
        headline: str,
        sub_headline: str,
        output_prefix: str,
        is_breaking: bool = True,
    ) -> str:
        """ÂÖ®„Ç∑„Éº„É≥„ÇíÁµêÂêà„Åó„Å¶ÊúÄÁµÇÂãïÁîª„Çí‰ΩúÊàêÔºàÈü≥Â£∞Èï∑„Å´Âêà„Çè„Åõ„Å¶„Çπ„É≠„ÉºË™øÊï¥Ôºâ"""
        
        console.print("\n[cyan]üé¨ ÊúÄÁµÇÂãïÁîª„ÇíÂêàÊàê‰∏≠...[/cyan]")
        
        # ÂãïÁîª„Åå„ÅÇ„Çã„Ç∑„Éº„É≥„Å†„ÅëÊäΩÂá∫
        valid_scenes = [s for s in scenes if s.video_path]
        if not valid_scenes:
            raise ValueError("ÊúâÂäπ„Å™ÂãïÁîª„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
        
        # ÊúÄÂàù„ÅÆÂãïÁîª„Åã„Çâ„Çµ„Ç§„Ç∫„ÇíÂèñÂæó
        probe = subprocess.run(
            ["ffprobe", "-v", "error", "-select_streams", "v:0",
             "-show_entries", "stream=width,height", "-of", "csv=p=0",
             valid_scenes[0].video_path],
            capture_output=True, text=True
        )
        size_parts = [p for p in probe.stdout.strip().split(',') if p]
        width, height = int(size_parts[0]), int(size_parts[1])
        
        # ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´Áî®„Éá„Ç£„É¨„ÇØ„Éà„É™
        temp_dir = self.dirs["temp"]
        
        # 1. ÂêÑ„Ç∑„Éº„É≥„Å´„Ç™„Éº„Éê„Éº„É¨„Ç§„Å®Â≠óÂπï„ÇíËøΩÂä†
        overlaid_videos = []
        
        for scene in valid_scenes:
            # „Éã„É•„Éº„Çπ„Ç™„Éº„Éê„Éº„É¨„Ç§‰ΩúÊàê
            overlay_path = str(temp_dir / f"overlay_{scene.index}.png")
            self.compositor.create_transparent_overlay(
                width=width, height=height,
                headline=headline,
                sub_headline=sub_headline,
                is_breaking=is_breaking,
                style="solid",
                output_path=overlay_path,
            )
            
            # Â≠óÂπï„ÇíËøΩÂä†
            overlay_img = Image.open(overlay_path).convert("RGBA")
            draw = ImageDraw.Draw(overlay_img)
            
            font = ImageFont.truetype(
                "/System/Library/Fonts/„Éí„É©„ÇÆ„ÉéËßí„Ç¥„Ç∑„ÉÉ„ÇØ W3.ttc",
                int(height * 0.032)
            )
            
            # Â≠óÂπï„ÇíË§áÊï∞Ë°å„Å´ÂàÜÂâ≤ÔºàÈï∑„ÅÑÂ†¥ÂêàÔºâ
            subtitle = scene.subtitle
            if len(subtitle) > 15:
                mid = len(subtitle) // 2
                for i in range(mid, 0, -1):
                    if subtitle[i] in '„Åå„ÅÆ„Çí„Å´„ÅØ„Åß„Å®„ÄÅ„ÄÇ':
                        mid = i + 1
                        break
                lines = [subtitle[:mid], subtitle[mid:]]
            else:
                lines = [subtitle]
            
            margin_x = int(width * 0.10)
            max_text_width = width - margin_x * 2
            line_height = int(height * 0.045)
            total_text_height = len(lines) * line_height
            start_y = (height - total_text_height) // 2
            
            for i, line in enumerate(lines):
                bbox = draw.textbbox((0, 0), line, font=font)
                text_w = bbox[2] - bbox[0]
                text_x = margin_x + (max_text_width - text_w) // 2
                y = start_y + i * line_height
                draw.text(
                    (text_x, y), line, font=font,
                    fill=(255, 255, 255, 255),
                    stroke_width=3,
                    stroke_fill=(0, 0, 0, 255)
                )
            
            scene_overlay_path = str(temp_dir / f"scene_overlay_{scene.index}.png")
            overlay_img.save(scene_overlay_path, "PNG")
            
            # FFmpeg„Åß„Ç™„Éº„Éê„Éº„É¨„Ç§ÂêàÊàê
            overlaid_path = str(temp_dir / f"overlaid_{scene.index}.mp4")
            subprocess.run([
                "ffmpeg", "-y",
                "-i", scene.video_path,
                "-i", scene_overlay_path,
                "-filter_complex", "[0:v][1:v]overlay=0:0",
                "-c:v", "libx264", "-preset", "fast", "-crf", "18",
                "-an", overlaid_path
            ], capture_output=True)
            
            overlaid_videos.append(overlaid_path)
            console.print(f"  ‚úÖ „Ç∑„Éº„É≥{scene.index + 1} „Ç™„Éº„Éê„Éº„É¨„Ç§ÈÅ©Áî®")
        
        # 2. ÂêÑ„Ç∑„Éº„É≥„ÅÆÈï∑„Åï„ÇíÂèñÂæó
        def get_duration(path):
            probe = subprocess.run(
                ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                 "-of", "default=noprint_wrappers=1:nokey=1", path],
                capture_output=True, text=True
            )
            return float(probe.stdout.strip())
        
        video_durations = [get_duration(v) for v in overlaid_videos]
        total_video_duration = sum(video_durations)
        
        console.print(f"  ÂãïÁîªÂêàË®à: {total_video_duration:.1f}Áßí, Èü≥Â£∞: {audio_duration:.1f}Áßí")
        
        # 3. Èü≥Â£∞„ÅåÈï∑„ÅÑÂ†¥Âêà„ÄÅÊúÄÂæå„ÅÆ„Ç∑„Éº„É≥„Çí„Çπ„É≠„Éº„Å´„Åó„Å¶Ë™øÊï¥
        if audio_duration > total_video_duration:
            other_scenes_duration = sum(video_durations[:-1])
            needed_last_scene = audio_duration - other_scenes_duration + 0.3
            slowdown_factor = needed_last_scene / video_durations[-1]
            
            console.print(f"  ÊúÄÂæå„ÅÆ„Ç∑„Éº„É≥„Çí {slowdown_factor:.2f}x „Çπ„É≠„Éº„Å´Ë™øÊï¥")
            
            # ÊúÄÂæå„ÅÆ„Ç∑„Éº„É≥„Çí„Çπ„É≠„ÉºÂåñ
            last_scene_slow = str(temp_dir / "last_scene_slow.mp4")
            subprocess.run([
                "ffmpeg", "-y", "-i", overlaid_videos[-1],
                "-filter:v", f"setpts={slowdown_factor}*PTS",
                "-c:v", "libx264", "-preset", "fast", "-crf", "18",
                "-an", last_scene_slow
            ], capture_output=True)
            overlaid_videos[-1] = last_scene_slow
        
        # 4. ÂãïÁîª„ÇíÁµêÂêàÔºàfilter_complexÊñπÂºèÔºâ
        inputs = []
        for v in overlaid_videos:
            inputs.extend(["-i", v])
        
        n = len(overlaid_videos)
        filter_str = "".join([f"[{i}:v]" for i in range(n)]) + f"concat=n={n}:v=1:a=0[v]"
        
        concat_video_path = str(temp_dir / "concat.mp4")
        cmd = ["ffmpeg", "-y"] + inputs + [
            "-filter_complex", filter_str,
            "-map", "[v]",
            "-c:v", "libx264", "-preset", "fast", "-crf", "18",
            concat_video_path
        ]
        subprocess.run(cmd, capture_output=True)
        console.print("  ‚úÖ ÂãïÁîªÁµêÂêàÂÆå‰∫Ü")
        
        # 5. Èü≥Â£∞„ÇíËøΩÂä†
        final_path = str(self.dirs["final"] / f"{output_prefix}_final.mp4")
        subprocess.run([
            "ffmpeg", "-y",
            "-i", concat_video_path,
            "-i", audio_path,
            "-c:v", "copy",
            "-c:a", "aac", "-b:a", "192k",
            "-shortest",
            final_path
        ], capture_output=True)
        
        console.print(f"\n[green]üéâ ÂÆåÊàê: {final_path}[/green]")
        
        return final_path
    
    def run(
        self,
        headline: str,
        sub_headline: str = "",
        scenes_data: list[dict] = None,
        closing_text: str = "",
        hook: str = "",  # „Éï„ÉÉ„ÇØÔºàÂÜíÈ†≠„ÅÆÂºï„ÅçÔºâ
        keywords: list[str] = None,  # Âº∑Ë™ø„Ç≠„Éº„ÉØ„Éº„Éâ
        visual_style: str = "",  # Êò†ÂÉè„Çπ„Çø„Ç§„É´
        article_text: str = "",  # ÂæåÊñπ‰∫íÊèõÁî®
        output_prefix: Optional[str] = None,
        is_breaking: bool = True,
        existing_images: list[str] = None,  # Êó¢Â≠òÁîªÂÉè„Éë„Çπ
    ) -> NewsVideoResult:
        """„Éë„Ç§„Éó„É©„Ç§„É≥ÂÖ®‰Ωì„ÇíÂÆüË°å
        
        Args:
            headline: „Éò„ÉÉ„Éâ„É©„Ç§„É≥
            sub_headline: „Çµ„Éñ„Éò„ÉÉ„Éâ„É©„Ç§„É≥
            scenes_data: „Ç∑„Éº„É≥ÊßãÊàê„Éá„Éº„ÇøÔºàÊñ∞ÂΩ¢ÂºèÔºâ
            closing_text: Á∑†„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥ÔºàÁúÅÁï•ÂèØÔºâ
            hook: ÂÜíÈ†≠„ÅÆ„Éï„ÉÉ„ÇØÔºàË¶ñËÅ¥ËÄÖ„ÇíÂºï„ÅçËæº„ÇÄ„Éï„É¨„Éº„Ç∫Ôºâ
            keywords: Âº∑Ë™ø„Åó„Åü„ÅÑ„Ç≠„Éº„ÉØ„Éº„Éâ„É™„Çπ„Éà
            visual_style: Êò†ÂÉèÂÖ®‰Ωì„ÅÆ„Çπ„Çø„Ç§„É´Ôºà‰æã: Ê∏©„Åã„Åø„ÅÆ„ÅÇ„ÇãÂÆ∂ÊóèÂÜôÁúüÈ¢®Ôºâ
            article_text: Ë®ò‰∫ãÊú¨ÊñáÔºàÂæåÊñπ‰∫íÊèõÁî®„ÄÅscenes_data„Åå„Å™„ÅÑÂ†¥Âêà„Å´‰ΩøÁî®Ôºâ
            output_prefix: Âá∫Âäõ„Éï„Ç°„Ç§„É´Âêç„Éó„É¨„Éï„Ç£„ÉÉ„ÇØ„Çπ
            is_breaking: BREAKING NEWS„Éê„Éä„ÉºË°®Á§∫
        """
        
        if output_prefix is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_prefix = f"news_{timestamp}"
        
        console.print("\n" + "=" * 50)
        console.print(f"[bold]üì∞ „Éã„É•„Éº„ÇπÂãïÁîªÁîüÊàê: {headline[:30]}...[/bold]")
        console.print("=" * 50)
        
        try:
            # „Ç∑„Éº„É≥ÊßãÊàê„Éá„Éº„Çø„Åå„ÅÇ„ÇãÂ†¥Âêà„ÅØÊñ∞„Éï„É≠„Éº
            if scenes_data and len(scenes_data) > 0:
                return self._run_with_scene_sync(
                    headline=headline,
                    sub_headline=sub_headline,
                    scenes_data=scenes_data,
                    closing_text=closing_text,
                    hook=hook,
                    keywords=keywords or [],
                    visual_style=visual_style,
                    output_prefix=output_prefix,
                    is_breaking=is_breaking,
                    existing_images=existing_images,
                )
            
            # ÂæåÊñπ‰∫íÊèõ: ÂæìÊù•„ÅÆ„Éï„É≠„ÉºÔºàarticle_text„Åã„ÇâÂàÜÊûêÔºâ
            if not article_text:
                return NewsVideoResult(
                    success=False,
                    error_message="scenes_data „Åæ„Åü„ÅØ article_text „ÅåÂøÖË¶Å„Åß„Åô",
                )
            
            # 1. Ë®ò‰∫ãÂàÜÊûê
            scenes = self.analyze_article(article_text, headline)
            
            # 2. ÁîªÂÉèÁîüÊàê
            scenes = self.generate_scene_images(scenes, output_prefix)
            
            # 3. ÂãïÁîªÁîüÊàê
            scenes = self.generate_scene_videos(scenes, output_prefix)
            
            # 4. „Éä„É¨„Éº„Ç∑„Éß„É≥ÁîüÊàêÔºàË®ò‰∫ãÂÖ®Êñá„Çí‰ΩøÁî®Ôºâ
            audio_path, audio_duration = self.generate_narration(
                article_text, output_prefix, closing_text=closing_text
            )
            
            # 5. ÊúÄÁµÇÂêàÊàêÔºàÈü≥Â£∞Èï∑„Å´Âêà„Çè„Åõ„Å¶„Çπ„É≠„ÉºË™øÊï¥Ôºâ
            final_path = self.compose_final_video(
                scenes=scenes,
                audio_path=audio_path,
                audio_duration=audio_duration,
                headline=headline,
                sub_headline=sub_headline,
                output_prefix=output_prefix,
                is_breaking=is_breaking,
            )
            
            # ÂãïÁîª„ÅÆÈï∑„Åï„ÇíÂèñÂæó
            probe = subprocess.run(
                ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                 "-of", "default=noprint_wrappers=1:nokey=1", final_path],
                capture_output=True, text=True
            )
            duration = float(probe.stdout.strip())
            
            return NewsVideoResult(
                success=True,
                video_path=final_path,
                scenes=scenes,
                audio_path=audio_path,
                duration_seconds=duration,
            )
            
        except Exception as e:
            console.print(f"[red]‚ùå „Ç®„É©„Éº: {e}[/red]")
            import traceback
            traceback.print_exc()
            return NewsVideoResult(
                success=False,
                error_message=str(e),
            )
    
    def _run_with_scene_sync(
        self,
        headline: str,
        sub_headline: str,
        scenes_data: list[dict],
        closing_text: str,
        hook: str,
        keywords: list[str],
        visual_style: str,
        output_prefix: str,
        is_breaking: bool,
        mood: str = "exciting",
        existing_images: list[str] = None,
    ) -> NewsVideoResult:
        """„Ç∑„Éº„É≥ÂêåÊúü„Éï„É≠„Éº: ÂêÑ„Ç∑„Éº„É≥„ÅÆ„Éä„É¨„Éº„Ç∑„Éß„É≥„Å®Êò†ÂÉè„ÇíÂêåÊúü„Åï„Åõ„Çã"""
        
        console.print(f"\n[cyan]üé¨ „Ç∑„Éº„É≥ÂêåÊúü„É¢„Éº„Éâ ({len(scenes_data)}„Ç∑„Éº„É≥)[/cyan]")
        console.print(f"[cyan]üí∞ „É¢„Éº„Éâ: {'Remotion (ÁÑ°Êñô)' if self.use_remotion else 'Luma (ÊúâÊñô)'}[/cyan]")
        if hook:
            console.print(f"[yellow]üé£ „Éï„ÉÉ„ÇØ: {hook}[/yellow]")
        if visual_style:
            console.print(f"[magenta]üé® „Çπ„Çø„Ç§„É´: {visual_style}[/magenta]")
        
        # 1. scenes_data„Åã„ÇâScene„Ç™„Éñ„Ç∏„Çß„ÇØ„Éà„Çí‰ΩúÊàê
        scenes = []
        for i, sd in enumerate(scenes_data):
            # visual_description„Åã„ÇâÁîªÂÉè„Éó„É≠„É≥„Éó„Éà„ÇíÁîüÊàêÔºàvisual_style„ÇíÁµ±‰∏ÄÈÅ©Áî®Ôºâ
            visual_desc = sd.get("visual_description", sd.get("title", ""))
            image_prompt = self._create_image_prompt(visual_desc, headline, visual_style)
            
            scene = Scene(
                index=i,
                description=visual_desc,
                image_prompt=image_prompt,
                video_prompt=f"Slow cinematic camera movement, {visual_desc}",
                subtitle=sd.get("narration", ""),  # Â≠óÂπïÔºàÂæå„ÅßRemotion„ÅßÂÖ®ÊñáË°®Á§∫Ôºâ
            )
            # „Éä„É¨„Éº„Ç∑„Éß„É≥„ÉÜ„Ç≠„Çπ„Éà„Å®Âº∑Ë™ø„ÉØ„Éº„Éâ„Çí‰øùÊåÅ
            scene.narration_text = sd.get("narration", "")
            scene.emphasis_word = sd.get("emphasis_word", "")
            # ÂêÑ„Ç∑„Éº„É≥„Å´Âõ∫Êúâ„ÅÆÁîªÂÉèÔºàimage_group „ÅØÂªÉÊ≠¢Ôºâ
            scenes.append(scene)
            console.print(f"  „Ç∑„Éº„É≥{i+1}: {visual_desc[:40]}...")
        
        # 2. ÂãïÁîªÁîüÊàêÔºàRemotion or LumaÔºâ
        if self.use_remotion:
            # Remotion: ÂÖà„Å´„Éä„É¨„Éº„Ç∑„Éß„É≥„ÇíÁîüÊàê„Åó„Å¶„ÄÅ„Åù„ÅÆÈï∑„Åï„Å´Âêà„Çè„Åõ„Çã
            console.print("\n[cyan]üé§ „Ç∑„Éº„É≥Âà•„Éä„É¨„Éº„Ç∑„Éß„É≥ÁîüÊàê‰∏≠ÔºàÂÖà„Å´Èü≥Â£∞Ôºâ...[/cyan]")
            for scene in scenes:
                narration_text = getattr(scene, 'narration_text', scene.subtitle)
                if narration_text:
                    audio_path = str(self.dirs["audio"] / f"{output_prefix}_scene{scene.index + 1}.mp3")
                    result = self.narration_gen.generate(text=narration_text, output_path=audio_path)
                    if result.success:
                        scene.audio_path = audio_path
                        scene.audio_duration = result.duration_seconds
                        console.print(f"  ‚úÖ „Ç∑„Éº„É≥{scene.index + 1}: {result.duration_seconds:.1f}Áßí")
            
            # ÁîªÂÉèÁîüÊàêÔºà„Éã„É•„Éº„ÇπÈ¢®„ÅÆËÉåÊôØÁî®Ôºâ„Åæ„Åü„ÅØÊó¢Â≠òÁîªÂÉè„Çí‰ΩøÁî®
            if existing_images and len(existing_images) >= len(scenes):
                console.print("\n[cyan]üñºÔ∏è Êó¢Â≠òÁîªÂÉè„Çí‰ΩøÁî®...[/cyan]")
                for i, scene in enumerate(scenes):
                    scene.image_path = str(Path(existing_images[i]).resolve())
                    console.print(f"  ‚úÖ „Ç∑„Éº„É≥{i+1}: {existing_images[i]}")
            else:
                console.print("\n[cyan]üñºÔ∏è ËÉåÊôØÁîªÂÉè„ÇíÁîüÊàê‰∏≠ (Flux)...[/cyan]")
                scenes = self.generate_scene_images(scenes, output_prefix)
            
            # Remotion „ÅßÂãïÁîªÁîüÊàêÔºàËÉåÊôØÁîªÂÉè + „Éã„É•„Éº„Çπ„Ç™„Éº„Éê„Éº„É¨„Ç§Ôºâ
            scenes = self.generate_scene_videos_remotion(
                scenes, output_prefix,
                headline=headline,
                sub_headline=sub_headline,
                is_breaking=is_breaking,
                news_style=True,
                mood=mood,
            )
        else:
            # Luma: ÁîªÂÉèÁîüÊàê ‚Üí ÂãïÁîªÁîüÊàêÔºàÊúâÊñôÔºâ
            scenes = self.generate_scene_images(scenes, output_prefix)
            scenes = self.generate_scene_videos(scenes, output_prefix)
        
        # 4. „Ç∑„Éº„É≥„Åî„Å®„Å´„Éä„É¨„Éº„Ç∑„Éß„É≥ÁîüÊàêÔºàRemotion„ÅÆÂ†¥Âêà„ÅØÊó¢„Å´ÁîüÊàêÊ∏à„ÅøÔºâ
        scene_audios = []
        total_audio_duration = 0
        
        if self.use_remotion:
            # Remotion: Êó¢„Å´ÁîüÊàêÊ∏à„Åø„Å™„ÅÆ„ÅßÈõÜË®à„ÅÆ„Åø
            for scene in scenes:
                if hasattr(scene, 'audio_path') and scene.audio_path:
                    scene_audios.append(scene.audio_path)
                    total_audio_duration += getattr(scene, 'audio_duration', 0)
        else:
            # Luma: „Åì„Åì„Åß„Éä„É¨„Éº„Ç∑„Éß„É≥ÁîüÊàê
            console.print("\n[cyan]üé§ „Ç∑„Éº„É≥Âà•„Éä„É¨„Éº„Ç∑„Éß„É≥ÁîüÊàê‰∏≠...[/cyan]")
            for scene in scenes:
                narration_text = getattr(scene, 'narration_text', scene.subtitle)
                if not narration_text:
                    continue
                    
                audio_path = str(self.dirs["audio"] / f"{output_prefix}_scene{scene.index + 1}.mp3")
                result = self.narration_gen.generate(text=narration_text, output_path=audio_path)
                
                if result.success:
                    scene.audio_path = audio_path
                    scene.audio_duration = result.duration_seconds
                    total_audio_duration += result.duration_seconds
                    scene_audios.append(audio_path)
                    console.print(f"  ‚úÖ „Ç∑„Éº„É≥{scene.index + 1}: {result.duration_seconds:.1f}Áßí")
                else:
                    console.print(f"  ‚ùå „Ç∑„Éº„É≥{scene.index + 1}: Èü≥Â£∞ÁîüÊàêÂ§±Êïó")
        
        # 5. Á∑†„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥
        if closing_text:
            closing_path = str(self.dirs["audio"] / f"{output_prefix}_closing.mp3")
            closing_result = self.narration_gen.generate(text=closing_text, output_path=closing_path)
            if closing_result.success:
                scene_audios.append(closing_path)
                total_audio_duration += closing_result.duration_seconds
                console.print(f"  ‚úÖ Á∑†„ÇÅ: {closing_result.duration_seconds:.1f}Áßí")
        
        # 6. ÂÖ®Èü≥Â£∞„ÇíÁµêÂêà
        console.print("\n[cyan]üîä Èü≥Â£∞ÁµêÂêà‰∏≠...[/cyan]")
        combined_audio = str(self.dirs["audio"] / f"{output_prefix}_combined.mp3")
        
        if len(scene_audios) > 1:
            # ffmpeg„ÅßÁµêÂêà
            concat_list = str(self.dirs["temp"] / "audio_concat.txt")
            with open(concat_list, "w") as f:
                for ap in scene_audios:
                    f.write(f"file '{ap}'\n")
            
            subprocess.run([
                "ffmpeg", "-y", "-f", "concat", "-safe", "0",
                "-i", concat_list, "-c", "copy", combined_audio
            ], capture_output=True)
        else:
            combined_audio = scene_audios[0] if scene_audios else None
        
        console.print(f"  ‚úÖ ÂêàË®àÈü≥Â£∞: {total_audio_duration:.1f}Áßí")
        
        # 6.5. „É†„Éº„ÉâÊ§úÂá∫ÔºàBGM„Éü„ÉÉ„ÇØ„Çπ„ÅØÊúÄÁµÇÂêàÊàê„ÅßË°å„ÅÜÔºâ
        all_narration = " ".join([getattr(s, 'narration_text', '') for s in scenes])
        mood = self.bgm_manager.detect_mood(headline, all_narration)
        console.print(f"[cyan]üé≠ Ê§úÂá∫„É†„Éº„Éâ: {mood.value}[/cyan]")
        
        # 7. ÊúÄÁµÇÂêàÊàêÔºà„Ç∑„Éº„É≥„Åî„Å®„Å´Èü≥Â£∞Èï∑„Å´Âêà„Çè„Åõ„ÇãÔºâ
        # Remotion + ÁîªÂÉèÁîüÊàê„ÅÆÂ†¥Âêà„ÅØ„Ç™„Éº„Éê„Éº„É¨„Ç§„Çí„Çπ„Ç≠„ÉÉ„ÉóÔºàRemotion „ÅßÊó¢„Å´Âê´„Åæ„Çå„Å¶„ÅÑ„ÇãÔºâ
        skip_overlay = self.use_remotion and any(s.image_path for s in scenes)
        
        final_path = self._compose_scene_synced_video(
            scenes=scenes,
            combined_audio=combined_audio,  # „É†„Éº„ÉâÊ§úÂá∫Áî®ÔºàBGM„Éü„ÉÉ„ÇØ„Çπ„ÅØÊúÄÁµÇÂêàÊàê„ÅßÔºâ
            total_audio_duration=total_audio_duration,
            headline=headline,
            sub_headline=sub_headline,
            output_prefix=output_prefix,
            is_breaking=is_breaking,
            skip_overlay=skip_overlay,
            mood=mood,  # Ê§úÂá∫„Åï„Çå„Åü„É†„Éº„Éâ„ÅßBGM„Éü„ÉÉ„ÇØ„Çπ
        )
        
        # ÂãïÁîª„ÅÆÈï∑„Åï„ÇíÂèñÂæó
        probe = subprocess.run(
            ["ffprobe", "-v", "error", "-show_entries", "format=duration",
             "-of", "default=noprint_wrappers=1:nokey=1", final_path],
            capture_output=True, text=True
        )
        duration = float(probe.stdout.strip()) if probe.stdout.strip() else total_audio_duration
        
        # DiscordÈÄöÁü•
        self._send_discord_notification(final_path, headline, duration)
        
        return NewsVideoResult(
            success=True,
            video_path=final_path,
            scenes=scenes,
            audio_path=combined_audio,
            duration_seconds=duration,
        )
    
    def _send_discord_notification(self, video_path: str, headline: str, duration: float) -> None:
        """Discord Webhook„ÅßÂÆåÊàêÈÄöÁü•„ÇíÈÄÅ‰ø°"""
        if not self.discord_webhook_url:
            return
        
        try:
            import requests
            
            # „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫„ÇíÂèñÂæó
            file_size = os.path.getsize(video_path) / (1024 * 1024)  # MB
            
            message = {
                "embeds": [{
                    "title": "üé¨ ÂãïÁîªÁîüÊàêÂÆå‰∫ÜÔºÅ",
                    "description": f"**{headline}**",
                    "color": 0x00ff00,  # Á∑ë
                    "fields": [
                        {"name": "üìÅ „Éï„Ç°„Ç§„É´", "value": f"`{os.path.basename(video_path)}`", "inline": True},
                        {"name": "‚è±Ô∏è Èï∑„Åï", "value": f"{duration:.1f}Áßí", "inline": True},
                        {"name": "üì¶ „Çµ„Ç§„Ç∫", "value": f"{file_size:.1f}MB", "inline": True},
                        {"name": "üìç „Éë„Çπ", "value": f"`{video_path}`", "inline": False},
                    ],
                    "footer": {"text": f"FJ News 24 ‚Ä¢ {self.channel_name}"}
                }]
            }
            
            response = requests.post(self.discord_webhook_url, json=message, timeout=10)
            if response.status_code == 204:
                console.print("[green]üì¢ DiscordÈÄöÁü•ÈÄÅ‰ø°ÂÆå‰∫Ü[/green]")
            else:
                console.print(f"[yellow]‚ö†Ô∏è DiscordÈÄöÁü•Â§±Êïó: {response.status_code}[/yellow]")
        except Exception as e:
            console.print(f"[yellow]‚ö†Ô∏è DiscordÈÄöÁü•„Ç®„É©„Éº: {e}[/yellow]")
    
    def _create_image_prompt(self, visual_desc: str, headline: str, visual_style: str = "") -> str:
        """visual_description„Åã„ÇâÁîªÂÉè„Éó„É≠„É≥„Éó„Éà„ÇíÁîüÊàêÔºà„Çπ„Çø„Ç§„É´Áµ±‰∏ÄÔºâ"""
        base = "Photorealistic, cinematic lighting, 4K quality, high detail"
        
        # visual_style„Åå„ÅÇ„Çå„Å∞ËøΩÂä†
        if visual_style:
            style_map = {
                "Ê∏©„Åã„Åø": "warm color palette, soft lighting, heartwarming atmosphere",
                "ÂÆ∂Êóè": "family-friendly, warm tones, emotional",
                "„Éâ„Ç≠„É•„É°„É≥„Çø„É™„Éº": "documentary style, natural lighting, realistic",
                "„Ç≥„Éü„Ç´„É´": "playful, bright colors, whimsical",
                "ÊÑüÂãï": "emotional, touching, cinematic, dramatic lighting",
                "È©ö„Åç": "dramatic, impactful, vivid colors",
            }
            # „Çπ„Çø„Ç§„É´„Ç≠„Éº„ÉØ„Éº„Éâ„Çí„Éû„ÉÉ„ÉÅ„É≥„Ç∞
            style_addition = ""
            for key, value in style_map.items():
                if key in visual_style:
                    style_addition = value
                    break
            if not style_addition:
                style_addition = visual_style  # „Åù„ÅÆ„Åæ„Åæ‰ΩøÁî®
            
            return f"{base}, {style_addition}, {visual_desc}"
        
        return f"{base}, {visual_desc}"
    
    def _compose_scene_synced_video(
        self,
        scenes: list[Scene],
        combined_audio: str,
        total_audio_duration: float,
        headline: str,
        sub_headline: str,
        output_prefix: str,
        is_breaking: bool,
        skip_overlay: bool = False,
        mood: MoodType = None,
    ) -> str:
        """„Ç∑„Éº„É≥ÂêåÊúü„ÅßÊúÄÁµÇÂãïÁîª„ÇíÂêàÊàê
        
        Args:
            skip_overlay: True „ÅÆÂ†¥Âêà„ÄÅ„Ç™„Éº„Éê„Éº„É¨„Ç§„ÇíËøΩÂä†„Åó„Å™„ÅÑÔºàRemotion „Éã„É•„Éº„ÇπÈ¢®„ÅÆÂ†¥ÂêàÔºâ
        """
        
        console.print("\n[cyan]üé¨ „Ç∑„Éº„É≥ÂêåÊúüÂêàÊàê‰∏≠...[/cyan]")
        
        valid_scenes = [s for s in scenes if s.video_path]
        if not valid_scenes:
            raise ValueError("ÊúâÂäπ„Å™„Ç∑„Éº„É≥ÂãïÁîª„Åå„ÅÇ„Çä„Åæ„Åõ„Çì")
        
        # ÂêÑ„Ç∑„Éº„É≥„ÅÆÁõÆÊ®ôÊôÇÈñì„ÇíË®àÁÆó
        num_scenes = len(valid_scenes)
        base_duration_per_scene = total_audio_duration / num_scenes
        
        console.print(f"  „Ç∑„Éº„É≥Êï∞: {num_scenes}, ÂêÑ„Ç∑„Éº„É≥ÁõÆÊ®ô: {base_duration_per_scene:.1f}Áßí")
        
        # ÂãïÁîª„Çµ„Ç§„Ç∫„ÇíÂèñÂæó
        probe = subprocess.run(
            ["ffprobe", "-v", "error", "-select_streams", "v:0",
             "-show_entries", "stream=width,height", "-of", "csv=p=0",
             valid_scenes[0].video_path],
            capture_output=True, text=True
        )
        size_parts = [p for p in probe.stdout.strip().split(',') if p]
        width, height = int(size_parts[0]), int(size_parts[1])
        
        temp_dir = self.dirs["temp"]
        
        # ÂêÑ„Ç∑„Éº„É≥„ÇíÁõÆÊ®ôÊôÇÈñì„Å´Ë™øÊï¥„Åó„Å¶„Ç™„Éº„Éê„Éº„É¨„Ç§ËøΩÂä†
        adjusted_videos = []
        
        for i, scene in enumerate(valid_scenes):
            # „Ç∑„Éº„É≥Âà•„ÅÆÈü≥Â£∞„Åå„ÅÇ„Çå„Å∞„ÄÅ„Åù„ÅÆÈï∑„Åï„Å´Âêà„Çè„Åõ„Çã
            target_duration = getattr(scene, 'audio_duration', base_duration_per_scene)
            
            # ÂãïÁîª„ÅÆÂÆüÈöõ„ÅÆÈï∑„Åï„ÇíÂèñÂæó
            probe = subprocess.run(
                ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                 "-of", "default=noprint_wrappers=1:nokey=1", scene.video_path],
                capture_output=True, text=True
            )
            actual_duration = float(probe.stdout.strip())
            
            # „Çπ„É≠„ÉºÁéá„ÇíË®àÁÆóÔºàÊúÄÂ§ß2ÂÄç„Åæ„ÅßÔºâ
            slowdown = min(target_duration / actual_duration, 2.0)
            
            adjusted_path = str(temp_dir / f"adjusted_{i}.mp4")
            
            # „Ç∑„Éº„É≥Èü≥Â£∞„ÇíÂèñÂæó
            scene_audio = getattr(scene, 'audio_path', None)
            
            if skip_overlay:
                # „Ç™„Éº„Éê„Éº„É¨„Ç§„Å™„ÅóÔºàRemotion „Éã„É•„Éº„ÇπÈ¢®„ÅÆÂ†¥Âêà„ÅØÊó¢„Å´Âê´„Åæ„Çå„Å¶„ÅÑ„ÇãÔºâ
                # ÂãïÁîª„ÅåÈü≥Â£∞„Çà„ÇäÁü≠„ÅÑÂ†¥Âêà„ÄÅÊúÄÂæå„ÅÆ„Éï„É¨„Éº„É†„ÇíÂª∂Èï∑„Åó„Å¶Èü≥Â£∞„Å´Âêà„Çè„Åõ„Çã
                adjusted_video_duration = actual_duration * slowdown
                pad_duration = max(0, target_duration - adjusted_video_duration + 0.1)  # 0.1Áßí‰ΩôË£ï
                filter_complex = f"setpts={slowdown}*PTS,tpad=stop_mode=clone:stop_duration={pad_duration}"
                
                if scene_audio and Path(scene_audio).exists():
                    # Èü≥Â£∞„ÇíÁõ¥Êé•Âüã„ÇÅËæº„ÅøÔºà„Ç∑„Éº„É≥„Åî„Å®„Å´ÂêåÊúüÔºâ
                    # Èü≥Â£∞„Çí44100Hz stereo„Å´Áµ±‰∏ÄÔºàconcat‰∫íÊèõÔºâ
                    # -t „ÅßÈü≥Â£∞„ÅÆÈï∑„Åï„Å´Ê≠£Á¢∫„Å´Âêà„Çè„Åõ„Çã
                    subprocess.run([
                        "ffmpeg", "-y",
                        "-i", scene.video_path,
                        "-i", scene_audio,
                        "-vf", filter_complex,
                        "-t", str(target_duration),
                        "-c:v", "libx264", "-preset", "fast",
                        "-c:a", "aac", "-b:a", "192k", "-ar", "44100", "-ac", "2",
                        "-map", "0:v", "-map", "1:a",
                        adjusted_path
                    ], capture_output=True)
                else:
                    # Èü≥Â£∞„Å™„Åó„ÅÆÂ†¥Âêà„ÇÇÁÑ°Èü≥„Éà„É©„ÉÉ„ÇØ„ÇíËøΩÂä†Ôºàconcat‰∫íÊèõÔºâ
                    subprocess.run([
                        "ffmpeg", "-y",
                        "-i", scene.video_path,
                        "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
                        "-vf", filter_complex,
                        "-t", str(target_duration),
                        "-c:v", "libx264", "-preset", "fast",
                        "-c:a", "aac", "-b:a", "192k",
                        adjusted_path
                    ], capture_output=True)
            else:
                # „Ç™„Éº„Éê„Éº„É¨„Ç§‰ΩúÊàêÔºàÊúÄÂàù„ÅÆ„Ç∑„Éº„É≥„ÅÆ„Åø„Éò„ÉÉ„Éâ„É©„Ç§„É≥Ë°®Á§∫Ôºâ
                overlay_path = str(temp_dir / f"overlay_{i}.png")
                self.compositor.create_transparent_overlay(
                    width=width,
                    height=height,
                    headline=headline if i == 0 else "",
                    sub_headline=sub_headline if i == 0 else "",
                    is_breaking=is_breaking and i == 0,
                    output_path=overlay_path,
                    style="gradient",
                )
                
                # ÂãïÁîªË™øÊï¥Ôºà„Çπ„É≠„Éº + „Ç™„Éº„Éê„Éº„É¨„Ç§ + Èü≥Â£∞Âüã„ÇÅËæº„ÅøÔºâ
                # ÂãïÁîª„ÅåÈü≥Â£∞„Çà„ÇäÁü≠„ÅÑÂ†¥Âêà„ÄÅÊúÄÂæå„ÅÆ„Éï„É¨„Éº„É†„ÇíÂª∂Èï∑
                adjusted_video_duration = actual_duration * slowdown
                pad_duration = max(0, target_duration - adjusted_video_duration + 0.1)
                filter_complex = f"[0:v]setpts={slowdown}*PTS,tpad=stop_mode=clone:stop_duration={pad_duration}[slowed];[slowed][1:v]overlay=0:0"
                
                if scene_audio and Path(scene_audio).exists():
                    # Èü≥Â£∞„Çí44100Hz stereo„Å´Áµ±‰∏ÄÔºàconcat‰∫íÊèõÔºâ
                    # -t „ÅßÈü≥Â£∞„ÅÆÈï∑„Åï„Å´Ê≠£Á¢∫„Å´Âêà„Çè„Åõ„Çã
                    subprocess.run([
                        "ffmpeg", "-y",
                        "-i", scene.video_path,
                        "-i", overlay_path,
                        "-i", scene_audio,
                        "-filter_complex", filter_complex,
                        "-t", str(target_duration),
                        "-c:v", "libx264", "-preset", "fast",
                        "-c:a", "aac", "-b:a", "192k", "-ar", "44100", "-ac", "2",
                        "-map", "[slowed]", "-map", "2:a",
                        adjusted_path
                    ], capture_output=True)
                else:
                    # Èü≥Â£∞„Å™„Åó„ÅÆÂ†¥Âêà„ÇÇÁÑ°Èü≥„Éà„É©„ÉÉ„ÇØ„ÇíËøΩÂä†Ôºàconcat‰∫íÊèõÔºâ
                    subprocess.run([
                        "ffmpeg", "-y",
                        "-i", scene.video_path,
                        "-i", overlay_path,
                        "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
                        "-filter_complex", filter_complex,
                        "-t", str(target_duration),
                        "-c:v", "libx264", "-preset", "fast",
                        "-c:a", "aac", "-b:a", "192k",
                        "-map", "[slowed]", "-map", "2:a",
                        adjusted_path
                    ], capture_output=True)
            
            adjusted_videos.append(adjusted_path)
            console.print(f"  ‚úÖ „Ç∑„Éº„É≥{i+1}: {actual_duration:.1f}Áßí ‚Üí {target_duration:.1f}Áßí (x{slowdown:.2f})")
        
        # „Ç§„É≥„Éà„É≠ÂãïÁîª„ÇíÁîüÊàê
        console.print("\n[cyan]üé¨ „Ç§„É≥„Éà„É≠ÁîüÊàê‰∏≠...[/cyan]")
        intro_path = str(temp_dir / "intro.mp4")
        self.intro_outro_gen.generate_intro_video(intro_path, temp_dir)
        console.print(f"  ‚úÖ „Ç§„É≥„Éà„É≠: 3Áßí")
        
        # „Ç¢„Ç¶„Éà„É≠ÂãïÁîª„ÇíÁîüÊàê
        console.print("[cyan]üé¨ „Ç¢„Ç¶„Éà„É≠ÁîüÊàê‰∏≠...[/cyan]")
        outro_path = str(temp_dir / "outro.mp4")
        self.intro_outro_gen.generate_outro_video(outro_path, temp_dir)
        console.print(f"  ‚úÖ „Ç¢„Ç¶„Éà„É≠: 4Áßí")
        
        # „Ç§„É≥„Éà„É≠„Éª„Ç¢„Ç¶„Éà„É≠„Å´ÁÑ°Èü≥„Éà„É©„ÉÉ„ÇØ„ÇíËøΩÂä†Ôºàconcat‰∫íÊèõÊÄß„ÅÆ„Åü„ÇÅÔºâ
        intro_with_audio = str(temp_dir / "intro_audio.mp4")
        outro_with_audio = str(temp_dir / "outro_audio.mp4")
        
        subprocess.run([
            "ffmpeg", "-y",
            "-i", intro_path,
            "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
            "-c:v", "copy", "-c:a", "aac", "-b:a", "192k",
            "-shortest",
            intro_with_audio
        ], capture_output=True)
        
        # „Ç¢„Ç¶„Éà„É≠„Å´Á∑†„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥„ÇíËøΩÂä†Ôºà„ÅÇ„Çå„Å∞Ôºâ
        closing_audio_path = str(self.dirs["audio"] / f"{output_prefix}_closing.mp3")
        if Path(closing_audio_path).exists():
            # Á∑†„ÇÅ„Éä„É¨„Éº„Ç∑„Éß„É≥„Çí44100Hz stereo„Å´Áµ±‰∏Ä„Åó„Å¶„Ç¢„Ç¶„Éà„É≠„Å´Âüã„ÇÅËæº„Åø
            subprocess.run([
                "ffmpeg", "-y",
                "-i", outro_path,
                "-i", closing_audio_path,
                "-c:v", "copy", "-c:a", "aac", "-b:a", "192k", "-ar", "44100", "-ac", "2",
                "-shortest",
                outro_with_audio
            ], capture_output=True)
        else:
            subprocess.run([
                "ffmpeg", "-y",
                "-i", outro_path,
                "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
                "-c:v", "copy", "-c:a", "aac", "-b:a", "192k",
                "-shortest",
                outro_with_audio
            ], capture_output=True)
        
        # ÂãïÁîª„ÇíÁµêÂêàÔºà„Ç§„É≥„Éà„É≠ + „É°„Ç§„É≥ + „Ç¢„Ç¶„Éà„É≠Ôºâ- ÂÖ®„Å¶Èü≥Â£∞‰ªò„Åç
        console.print("\n[cyan]üé¨ ÂÖ®‰ΩìÁµêÂêà‰∏≠...[/cyan]")
        concat_list = str(temp_dir / "video_concat.txt")
        with open(concat_list, "w") as f:
            f.write(f"file '{intro_with_audio}'\n")
            for vp in adjusted_videos:
                f.write(f"file '{vp}'\n")
            f.write(f"file '{outro_with_audio}'\n")
        
        concat_video = str(temp_dir / f"{output_prefix}_concat.mp4")
        subprocess.run([
            "ffmpeg", "-y", "-f", "concat", "-safe", "0",
            "-i", concat_list, "-c", "copy", concat_video
        ], capture_output=True)
        
        final_path = str(self.dirs["final"] / f"{output_prefix}_final.mp4")
        
        # BGM„Éü„ÉÉ„ÇØ„ÇπÔºàcombined_audio„ÅØBGM„Éü„ÉÉ„ÇØ„ÇπÊ∏à„Åø„ÅÆÂ†¥ÂêàÔºâ
        if combined_audio and Path(combined_audio).exists():
            # ÂãïÁîª„ÅÆÈü≥Â£∞„ÇíÊäΩÂá∫
            video_audio = str(temp_dir / f"{output_prefix}_video_audio.mp3")
            subprocess.run([
                "ffmpeg", "-y", "-i", concat_video,
                "-vn", "-c:a", "libmp3lame", "-b:a", "192k",
                video_audio
            ], capture_output=True)
            
            # BGM„Å®„Éü„ÉÉ„ÇØ„ÇπÔºàÂãïÁîªÈü≥Â£∞„ÇíÂÑ™ÂÖàÔºâ
            # Ê§úÂá∫„Åï„Çå„Åü„É†„Éº„Éâ„Çí‰ΩøÁî®„ÄÅ„Å™„Åë„Çå„Å∞ NEUTRAL
            bgm_mood = mood if mood else MoodType.NEUTRAL
            bgm_track = self.bgm_manager.get_bgm(bgm_mood)
            console.print(f"  üéµ BGM„Éü„ÉÉ„ÇØ„Çπ‰∏≠... ({bgm_mood.value})")
            if bgm_track and Path(bgm_track.path).exists():
                mixed_audio = str(temp_dir / f"{output_prefix}_final_mixed.mp3")
                self.bgm_manager.mix_audio(
                    narration_path=video_audio,
                    bgm_path=bgm_track.path,
                    output_path=mixed_audio,
                    narration_volume=1.0,
                    bgm_volume=0.15,
                )
                # „Éü„ÉÉ„ÇØ„ÇπÊ∏à„ÅøÈü≥Â£∞„ÇíÂãïÁîª„Å´ÈÅ©Áî®
                subprocess.run([
                    "ffmpeg", "-y",
                    "-i", concat_video,
                    "-i", mixed_audio,
                    "-c:v", "copy", "-c:a", "aac", "-b:a", "192k",
                    "-map", "0:v", "-map", "1:a",
                    final_path
                ], capture_output=True)
            else:
                subprocess.run(["cp", concat_video, final_path])
        else:
            subprocess.run(["cp", concat_video, final_path])
        
        console.print(f"\n[green]üéâ ÂÆåÊàê: {final_path}[/green]")
        
        return final_path


# CLIÁî®
if __name__ == "__main__":
    import sys
    
    pipeline = NewsVideoPipeline()
    
    # „ÉÜ„Çπ„ÉàÁî®
    result = pipeline.run(
        article_text="""
        „Çπ„Éö„Ç§„É≥„ÅßË°åÊñπ‰∏çÊòé„Å´„Å™„Å£„ÅüÁå´„Åå„ÄÅ5„É∂Êúà„Åã„Åë„Å¶250„Ç≠„É≠„ÇíÊ≠©„Åç„ÄÅ
        „Éï„É©„É≥„Çπ„ÅÆËá™ÂÆÖ„Å´Â∏∞ÈÇÑ„Åó„Åæ„Åó„Åü„ÄÇÈ£º„ÅÑ‰∏ª„ÅÆ„Éï„Ç°„Éì„Ç¢„É≥„Åï„Çì„ÅØ„ÄÅ
        ÊÑõÁå´„Éü„Éå„Ç∑„É•„ÅåÊàª„Å£„Å¶„Åç„ÅüÊôÇ„ÄÅ‰ø°„Åò„Çâ„Çå„Å™„Åã„Å£„Åü„Å®Ë™û„Å£„Å¶„ÅÑ„Åæ„Åô„ÄÇ
        Áå´„ÅØÂ∞ë„ÅóÁó©„Åõ„Å¶„ÅÑ„Åæ„Åó„Åü„Åå„ÄÅÂÖÉÊ∞ó„Å™ÊßòÂ≠ê„Åß„Åó„Åü„ÄÇ
        """,
        headline="Áå´„Åå250kmÊ≠©„ÅÑ„Å¶„Çπ„Éö„Ç§„É≥„Åã„Çâ„Éï„É©„É≥„Çπ„ÅÆËá™ÂÆÖ„Å´Â∏∞ÈÇÑ",
        sub_headline="5„É∂Êúà„Åã„Åë„Å¶155„Éû„Ç§„É´„ÇíË∏èÁ†¥",
        output_prefix="cat_journey",
    )
    
    print(f"\nÁµêÊûú: {'ÊàêÂäü' if result.success else 'Â§±Êïó'}")
    if result.success:
        print(f"ÂãïÁîª: {result.video_path}")
        print(f"Èï∑„Åï: {result.duration_seconds:.1f}Áßí")
