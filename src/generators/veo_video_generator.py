"""Veo 3.1 å‹•ç”»ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - ç”»åƒã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆ"""

import os
import time
from pathlib import Path
from dataclasses import dataclass
from typing import Optional

from google import genai
from google.genai import types

from ..config import config, VIDEOS_DIR
from ..logger import setup_logger

logger = setup_logger("veo_video_generator")


@dataclass
class VeoVideoResult:
    """Veoå‹•ç”»ç”Ÿæˆçµæœ"""
    success: bool
    output_path: Optional[str] = None
    duration: float = 0.0
    error_message: Optional[str] = None
    generation_time: float = 0.0


class VeoVideoGenerator:
    """Veo 3.1 ã§ç”»åƒã‹ã‚‰è¶…ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªå‹•ç”»ã‚’ç”Ÿæˆ"""

    # ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒ»ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—åˆ¥ã®è¶…ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
    # é‡è¦: é™æ­¢ç”»ã£ã½ãè¦‹ãˆãªã„ã‚ˆã†ã«ã€å‹•ãã‚’å…·ä½“çš„ã«æŒ‡ç¤ºã™ã‚‹
    MOVEMENT_PROMPTS = {
        "æ”¿æ²»": {
            "intro": (
                "Cinematic drone shot slowly descending towards Japanese Diet building, "
                "camera continuously moving forward and down, clouds drifting across sky, "
                "trees swaying in gentle wind, flags fluttering on poles, "
                "golden hour light shifting across the building facade, "
                "birds flying across frame, shadow of drone visible moving on ground, "
                "gimbal stabilized smooth motion, real broadcast news footage feel"
            ),
            "detail": (
                "Steadicam shot gliding through government corridor, "
                "camera pushing forward at walking pace, people passing by in both directions, "
                "shadows moving as we pass windows, reflections sliding on polished floor, "
                "dust particles visible in light beams from windows, "
                "focus smoothly shifts from foreground to background, "
                "realistic indoor lighting with subtle flicker"
            ),
            "outro": (
                "Crane shot rising above the Diet building, camera rotating 15 degrees, "
                "city revealing below as we ascend, car lights streaming on roads, "
                "clouds moving overhead in accelerated motion, "
                "building lights turning on as dusk settles, "
                "ambient city sounds implied, gradual zoom out to wide shot"
            ),
        },
        "çµŒæ¸ˆ": {
            "intro": (
                "Hyperlapse through Marunouchi financial district, camera moving forward, "
                "pedestrians walking in accelerated motion, traffic flowing continuously, "
                "neon signs flickering and pulsing, rain drops streaking on camera lens, "
                "reflections rippling on wet pavement, steam rising from vents, "
                "streetlights glowing with halos, real urban documentary feel"
            ),
            "detail": (
                "Camera orbiting around trading desk monitors, continuous rotation, "
                "stock numbers scrolling rapidly, green and red prices updating, "
                "reflections on multiple glass screens, keyboard keys clicking implied, "
                "shallow depth with background traders moving, screen glow illuminating faces, "
                "real financial news room atmosphere"
            ),
            "outro": (
                "Aerial view ascending above Tokyo skyline, camera tilting up, "
                "office building lights twinkling like stars, "
                "trains moving along tracks below, helicopter passing in distance, "
                "clouds moving across moon, gradual color shift to night blue"
            ),
        },
        "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": {
            "intro": (
                "Camera flying forward through 3D data visualization space, "
                "data streams flowing past camera continuously, nodes connecting with light pulses, "
                "holographic UI panels materializing and dissolving, "
                "particles swirling in helical patterns, circuit patterns pulsing with electricity, "
                "camera weaving between floating data structures, "
                "lens flares from bright nodes, sci-fi movie quality"
            ),
            "detail": (
                "Camera pushing towards holographic display, focus pulling through layers, "
                "digital code waterfalls cascading down, graphs animating with new data, "
                "neural network visualization with firing synapses, "
                "rotating 3D models of technology, ambient particle field drifting, "
                "reflection of display on glass surface, futuristic UI interaction"
            ),
            "outro": (
                "Camera pulling back through infinite digital layers, zooming out continuously, "
                "data networks shrinking to points of light, global connection web visible, "
                "transition from micro to macro scale, stars emerging in background, "
                "final reveal of Earth with data flowing between continents"
            ),
        },
        "å›½éš›": {
            "intro": (
                "Earth rotating slowly from orbital view, camera drifting right, "
                "clouds swirling over continents, city lights twinkling on night side, "
                "aurora borealis rippling over poles, sun rising creating lens flare, "
                "satellites visible as moving points of light, "
                "space debris tumbling past, realistic space footage quality"
            ),
            "detail": (
                "Camera flying across 3D world map, moving between continents, "
                "connection lines animating between cities, pulsing nodes indicating activity, "
                "terrain elevation rising as camera passes, ocean waves visible below, "
                "news graphics appearing with country labels, "
                "smooth camera arc over regions of interest"
            ),
            "outro": (
                "Camera zooming out from Earth, moon entering frame, "
                "stars becoming visible in background, satellite passing in foreground, "
                "Earth rotating continuously, space station visible as bright point, "
                "cosmic perspective establishing, gentle fade to starfield"
            ),
        },
        "ç§‘å­¦": {
            "intro": (
                "Microscope view diving into cellular world, camera pushing through membrane, "
                "organelles floating and rotating, cilia waving rhythmically, "
                "bioluminescent flashes occurring randomly, DNA strand rotating slowly, "
                "particles drifting in cellular fluid, focus shifting through depth layers, "
                "scientific documentary visual quality"
            ),
            "detail": (
                "Camera moving through molecular landscape, atoms vibrating with energy, "
                "chemical bonds forming with light emissions, electron clouds pulsing, "
                "crystalline structures rotating, liquid nitrogen mist flowing, "
                "laser beams scanning, data readouts updating in overlay, "
                "laboratory atmosphere with equipment humming"
            ),
            "outro": (
                "Scale transition from microscopic to human to cosmic, continuous zoom out, "
                "fractals unfolding and morphing, cells becoming organs becoming bodies, "
                "then rising above Earth into space, galaxies spiraling, "
                "universe expanding perspective, sense of scientific wonder"
            ),
        },
        "ã‚¹ãƒãƒ¼ãƒ„": {
            "intro": (
                "Stadium pan shot with crowd creating wave motion, camera on crane swinging, "
                "spotlights sweeping across field, confetti falling continuously, "
                "flags waving in stands, players warming up in distance, "
                "breath visible in cool air, real sports broadcast atmosphere"
            ),
            "detail": (
                "Slow motion capture of athletic movement, athlete body in motion, "
                "muscle fibers visible tensing, sweat droplets suspended then falling, "
                "equipment moving through air, fabric rippling with wind resistance, "
                "crowd blurred in background, focus locked on action, "
                "high speed camera feel, dramatic sports photography"
            ),
            "outro": (
                "Victory celebration with fireworks bursting, confetti shower continuous, "
                "camera crane rising above celebrating crowd, "
                "stadium lights pulsing, smoke from pyrotechnics drifting, "
                "tears of joy visible, golden sunset lighting, triumphant moment"
            ),
        },
        "default": {
            "intro": (
                "Smooth tracking shot through abstract environment, camera gliding forward, "
                "volumetric light beams shifting slowly, dust particles floating in air, "
                "atmospheric fog rolling gently, lens flares from light sources, "
                "depth layers moving at different parallax speeds, "
                "cinematic establishing shot, professional documentary quality"
            ),
            "detail": (
                "Camera push with continuous motion, focus pulling through scene layers, "
                "environmental elements swaying naturally with implied wind, "
                "light beams rotating slowly, shadows moving across surfaces, "
                "particles drifting through frame, reflections rippling, "
                "texture details revealed as camera approaches"
            ),
            "outro": (
                "Graceful camera pull-back with continuous motion, elements settling, "
                "wind effect on floating particles, light fading to amber, "
                "gentle camera rotation as we retreat, perspective widening, "
                "ambient atmosphere deepening, professional fade out"
            ),
        },
    }

    # å‹•çš„è¦ç´ ã®ãƒ—ãƒ¼ãƒ«ï¼ˆãƒ©ãƒ³ãƒ€ãƒ ã«è¿½åŠ ï¼‰
    DYNAMIC_ELEMENTS = [
        "realistic motion blur on moving objects",
        "subtle natural camera shake for authenticity",
        "professional color grading with cinematic LUT",
        "volumetric fog and atmospheric scattering",
        "dynamic lighting that shifts and evolves",
        "parallax depth layers creating 3D effect",
        "realistic physics simulation on particles",
        "cinematic lens effects including anamorphic flares",
        "smooth 60fps fluid motion",
        "ray-traced reflections and shadows",
        "ambient occlusion for depth",
        "film grain for cinematic texture",
    ]

    def __init__(self, model: str = "veo-3.1"):
        """Veoå‹•ç”»ç”Ÿæˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–

        Args:
            model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ« ("veo-3.1" ã¾ãŸã¯ "veo-3-fast")
        """
        if not config.gemini.api_key:
            raise ValueError("GEMINI_API_KEY is not set")

        self.client = genai.Client(api_key=config.gemini.api_key)
        self.model = model  # Veo 3.1 (Image-to-Videoå¯¾å¿œ)
        self.output_dir = VIDEOS_DIR
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
        self.last_request_time = 0
        self.min_request_interval = 60  # 1åˆ†é–“éš”ï¼ˆVeo 3.1ã¯èª²é‡‘ãƒ—ãƒ©ãƒ³ã§ã‚‚åˆ¶é™ã‚ã‚Šï¼‰

        logger.info(f"VeoVideoGenerator initialized with {self.model}")

    def _wait_for_rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å›é¿ã™ã‚‹ãŸã‚å¾…æ©Ÿ"""
        elapsed = time.time() - self.last_request_time
        if elapsed < self.min_request_interval:
            wait_time = self.min_request_interval - elapsed
            logger.info(f"Rate limit: waiting {wait_time:.1f}s")
            time.sleep(wait_time)
        self.last_request_time = time.time()

    def _enhance_prompt_for_maximum_motion(
        self,
        base_prompt: str,
        motion_strength: float = 0.9,
        guidance_scale: float = 8.0,
    ) -> str:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å¼·åŒ–ã—ã¦æœ€å¤§é™ã®å‹•ãã‚’å¼•ãå‡ºã™

        Veo 3.1ã¯ä¸»ã«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å‹•ãã‚’åˆ¶å¾¡ã™ã‚‹ãŸã‚ã€
        ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è©³ç´°ã«ã™ã‚‹ã“ã¨ã§æœ¬ç‰©ã®å‹•ç”»ã‚‰ã—ã•ã‚’å®Ÿç¾ã™ã‚‹

        Args:
            base_prompt: åŸºæœ¬ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            motion_strength: å‹•ãã®å¼·ã• (0.0-1.0)
            guidance_scale: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸ã®å¿ å®Ÿåº¦

        Returns:
            å¼·åŒ–ã•ã‚ŒãŸãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        # å‹•ãã®å¼·ã•ã«å¿œã˜ãŸä¿®é£¾å­
        if motion_strength >= 0.8:
            motion_modifiers = [
                "continuous fluid motion throughout",
                "dynamic camera movement",
                "constant subtle motion in all elements",
                "realistic physics-based movement",
                "natural swaying and flowing motion",
                "parallax effect with depth layers moving at different speeds",
            ]
        elif motion_strength >= 0.5:
            motion_modifiers = [
                "smooth gradual motion",
                "gentle camera pan",
                "subtle environmental movement",
                "soft swaying elements",
            ]
        else:
            motion_modifiers = [
                "minimal subtle motion",
                "slow gentle movement",
            ]

        # ã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ã®æŒ‡ç¤ºï¼ˆé‡è¦: VeoãŒé™æ­¢ç”»ã£ã½ããªã‚‰ãªã„ã‚ˆã†ã«ã™ã‚‹ï¼‰
        camera_instructions = [
            "camera slowly pushes forward creating depth",
            "slight camera drift to the right",
            "gentle zoom progression",
            "handheld camera feel with subtle shake",
            "cinematic dolly movement",
        ]

        # ç’°å¢ƒã®å‹•ãã®æŒ‡ç¤º
        environment_motion = [
            "wind gently moving particles and elements",
            "light rays shifting slowly",
            "atmospheric haze drifting",
            "reflections rippling subtly",
            "shadows slowly shifting with light source",
            "floating dust particles catching light",
        ]

        # å‹•ãã®å¼·ã•ã«å¿œã˜ã¦è¦ç´ ã‚’é¸æŠ
        import random
        num_motion = min(3, int(motion_strength * 4))
        num_camera = min(2, int(motion_strength * 3))
        num_env = min(2, int(motion_strength * 3))

        selected_motion = random.sample(motion_modifiers, min(num_motion, len(motion_modifiers)))
        selected_camera = random.sample(camera_instructions, min(num_camera, len(camera_instructions)))
        selected_env = random.sample(environment_motion, min(num_env, len(environment_motion)))

        # å“è³ªã¨ãƒªã‚¢ãƒªã‚ºãƒ ã®æŒ‡ç¤º
        quality_suffix = (
            "photorealistic rendering, natural motion blur on moving elements, "
            "broadcast quality cinematography, film-like color grading, "
            "seamless 30fps fluid motion, professional videography"
        )

        # çµ¶å¯¾ã«é¿ã‘ã‚‹ã¹ãã“ã¨ã®æ˜ç¤ºï¼ˆãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆçš„ã«ä½¿ã†ï¼‰
        # Note: ã“ã‚Œã¯å®Ÿéš›ã®ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§ã¯ãªãã€æŒ‡ç¤ºã¨ã—ã¦å«ã‚ã‚‹
        anti_static_instruction = (
            "NOT a static image, NOT a slideshow, this is a REAL moving video, "
            "everything should have natural motion"
        )

        # æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        enhanced_parts = [
            base_prompt,
            "IMPORTANT: " + anti_static_instruction,
            "Motion: " + ", ".join(selected_motion),
            "Camera: " + ", ".join(selected_camera),
            "Environment: " + ", ".join(selected_env),
            quality_suffix,
        ]

        enhanced_prompt = ". ".join(enhanced_parts)

        return enhanced_prompt

    def generate_from_image(
        self,
        image_path: str,
        output_path: str = None,
        prompt: str = "",
        duration: int = 8,
        aspect_ratio: str = "16:9",
        resolution: str = "1080p",
        include_audio: bool = True,
        motion_strength: float = 0.9,
        guidance_scale: float = 8.0,
    ) -> VeoVideoResult:
        """ç”»åƒã‹ã‚‰è¶…ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªå‹•ç”»ã‚’ç”Ÿæˆï¼ˆVeo 3.1 Image-to-Video APIï¼‰

        Args:
            image_path: å…¥åŠ›ç”»åƒã®ãƒ‘ã‚¹
            output_path: å‡ºåŠ›å‹•ç”»ã®ãƒ‘ã‚¹
            prompt: å‹•ç”»ç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆã‚«ãƒ¡ãƒ©ãƒ¯ãƒ¼ã‚¯ãªã©ï¼‰
            duration: å‹•ç”»ã®é•·ã•ï¼ˆç§’ï¼‰5-8ç§’æ¨å¥¨
            aspect_ratio: ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯” ("16:9", "9:16", "1:1")
            resolution: è§£åƒåº¦ ("720p", "1080p")
            include_audio: éŸ³éŸ¿åŠ¹æœã‚’è‡ªå‹•è¿½åŠ ã™ã‚‹ã‹
            motion_strength: å‹•ãã®å¼·ã• (0.0-1.0) é«˜ã„ã»ã©å¤§ããå‹•ã
            guidance_scale: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¸ã®å¿ å®Ÿåº¦ (1.0-20.0) é«˜ã„ã»ã©ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé€šã‚Š

        Returns:
            VeoVideoResult
        """
        start_time = time.time()

        if not Path(image_path).exists():
            return VeoVideoResult(
                success=False,
                error_message=f"Image not found: {image_path}",
            )

        if output_path is None:
            stem = Path(image_path).stem
            output_path = str(self.output_dir / f"{stem}_veo.mp4")

        self._wait_for_rate_limit()

        try:
            # è©³ç´°ãªãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
            logger.info("=" * 60)
            logger.info("ğŸ¬ VEO 3.1 DYNAMIC VIDEO GENERATION")
            logger.info("=" * 60)
            logger.info(f"Model: {self.model}")
            logger.info(f"Image: {Path(image_path).name}")
            logger.info(f"Duration: {duration}s | Resolution: {resolution}")
            logger.info(f"Aspect Ratio: {aspect_ratio} | Audio: {include_audio}")
            logger.info(f"Motion Strength: {motion_strength} | Guidance: {guidance_scale}")
            logger.info("-" * 60)
            logger.info(f"PROMPT:\n{prompt}")
            logger.info("=" * 60)

            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(image_path, "rb") as f:
                image_data = f.read()

            image_size_kb = len(image_data) / 1024
            logger.info(f"Image size: {image_size_kb:.1f} KB")

            # MIMEã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
            image_suffix = Path(image_path).suffix.lower()
            mime_type = {
                ".png": "image/png",
                ".jpg": "image/jpeg",
                ".jpeg": "image/jpeg",
                ".webp": "image/webp",
            }.get(image_suffix, "image/png")

            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã•ã‚‰ã«å¼·åŒ–ï¼ˆå‹•ãã‚’æœ€å¤§é™ã«å¼•ãå‡ºã™ï¼‰
            enhanced_prompt = self._enhance_prompt_for_maximum_motion(
                prompt, motion_strength, guidance_scale
            )
            logger.info(f"Enhanced prompt length: {len(enhanced_prompt)} chars")

            # Veo 3.1 Image-to-Video APIï¼ˆéåŒæœŸæ“ä½œï¼‰
            logger.info("Calling Veo 3.1 API...")
            operation = self.client.models.generate_video(
                model=self.model,
                prompt=enhanced_prompt,
                config=types.GenerateVideoConfig(
                    image=types.Image(
                        image_bytes=image_data,
                        mime_type=mime_type,
                    ),
                    aspect_ratio=aspect_ratio,
                    # Note: Veo API ã®åˆ©ç”¨å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯é™å®šçš„
                    # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å‹•ãã‚’åˆ¶å¾¡ã™ã‚‹ã“ã¨ãŒä¸»ãªæ‰‹æ³•
                ),
            )

            logger.info("â³ Waiting for Veo 3.1 video generation to complete...")
            logger.info("   (This typically takes 2-5 minutes for high-quality video)")

            # æ“ä½œã®å®Œäº†ã‚’å¾…æ©Ÿï¼ˆãƒãƒ¼ãƒªãƒ³ã‚°ï¼‰
            poll_count = 0
            poll_start = time.time()
            while not operation.done:
                poll_count += 1
                elapsed_mins = (time.time() - poll_start) / 60
                logger.info(f"   Processing... (poll #{poll_count}, {elapsed_mins:.1f} min elapsed)")
                time.sleep(10)
                operation = self.client.operations.get(operation)

            total_wait = time.time() - poll_start
            logger.info(f"âœ… Veo API responded after {total_wait:.1f}s ({poll_count} polls)")

            # çµæœã‚’å–å¾—
            if operation.error:
                logger.error(f"âŒ Veo API returned error: {operation.error}")
                raise ValueError(f"Generation failed: {operation.error}")

            response = operation.response

            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ§‹é€ ã‚’ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
            logger.debug(f"Response type: {type(response)}")
            logger.debug(f"Response attributes: {dir(response)}")

            # å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            video_data = None
            video_source = "unknown"

            if hasattr(response, 'generated_videos') and response.generated_videos:
                logger.info(f"ğŸ“¹ Found {len(response.generated_videos)} generated video(s)")
                video = response.generated_videos[0]
                logger.debug(f"Video object attributes: {dir(video)}")

                if hasattr(video, 'video'):
                    video_data = video.video
                    video_source = "generated_videos[0].video"
                elif hasattr(video, 'video_bytes'):
                    video_data = video.video_bytes
                    video_source = "generated_videos[0].video_bytes"

            if not video_data:
                logger.warning("âš ï¸ No video in primary response format, checking alternatives...")
                # ä»£æ›¿ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚’ç¢ºèª
                if hasattr(response, 'video'):
                    video_data = response.video
                    video_source = "response.video"
                    logger.info("Found video in response.video")
                elif hasattr(response, 'candidates') and response.candidates:
                    logger.info(f"Checking {len(response.candidates)} candidates...")
                    for part in response.candidates[0].content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            mime = getattr(part.inline_data, 'mime_type', '')
                            logger.debug(f"Part mime_type: {mime}")
                            if 'video' in mime:
                                video_data = part.inline_data.data
                                video_source = f"candidates[0].content.parts (mime: {mime})"
                                break

            if not video_data:
                logger.error("âŒ No video data in any response format")
                logger.error("   Response structure inspection:")
                logger.error(f"   - has generated_videos: {hasattr(response, 'generated_videos')}")
                logger.error(f"   - has video: {hasattr(response, 'video')}")
                logger.error(f"   - has candidates: {hasattr(response, 'candidates')}")
                return VeoVideoResult(
                    success=False,
                    error_message="No video generated - Veo API returned empty response",
                    generation_time=time.time() - start_time,
                )

            logger.info(f"âœ… Video data extracted from: {video_source}")

            # å‹•ç”»ã‚’ä¿å­˜
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)

            if isinstance(video_data, bytes):
                video_size_mb = len(video_data) / (1024 * 1024)
                logger.info(f"ğŸ’¾ Saving video ({video_size_mb:.2f} MB) as bytes...")
                with open(output_path, "wb") as f:
                    f.write(video_data)
            else:
                # base64ã®å ´åˆ
                import base64
                logger.info("ğŸ’¾ Saving video (base64 encoded)...")
                decoded_data = base64.b64decode(video_data)
                video_size_mb = len(decoded_data) / (1024 * 1024)
                logger.info(f"   Decoded size: {video_size_mb:.2f} MB")
                with open(output_path, "wb") as f:
                    f.write(decoded_data)

            generation_time = time.time() - start_time

            # æœ€çµ‚ç¢ºèª
            if Path(output_path).exists():
                final_size = Path(output_path).stat().st_size / (1024 * 1024)
                logger.info("=" * 60)
                logger.info("ğŸ‰ VEO 3.1 VIDEO GENERATION SUCCESS")
                logger.info("=" * 60)
                logger.info(f"   Output: {output_path}")
                logger.info(f"   Size: {final_size:.2f} MB")
                logger.info(f"   Generation time: {generation_time:.1f}s")
                logger.info("=" * 60)
            else:
                logger.error(f"âŒ File not created: {output_path}")

            return VeoVideoResult(
                success=True,
                output_path=output_path,
                duration=duration,
                generation_time=generation_time,
            )

        except Exception as e:
            logger.error(f"Video generation failed: {e}")
            import traceback
            logger.debug(traceback.format_exc())

            return VeoVideoResult(
                success=False,
                error_message=str(e),
                generation_time=time.time() - start_time,
            )

    def generate_from_prompt(
        self,
        prompt: str,
        output_path: str = None,
        duration: int = 5,
        aspect_ratio: str = "16:9",
        resolution: str = "1080p",
    ) -> VeoVideoResult:
        """ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã¿ã‹ã‚‰å‹•ç”»ã‚’ç”Ÿæˆï¼ˆText-to-Videoï¼‰

        Args:
            prompt: å‹•ç”»ç”Ÿæˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            output_path: å‡ºåŠ›å‹•ç”»ã®ãƒ‘ã‚¹
            duration: å‹•ç”»ã®é•·ã•ï¼ˆç§’ï¼‰
            aspect_ratio: ã‚¢ã‚¹ãƒšã‚¯ãƒˆæ¯”
            resolution: è§£åƒåº¦

        Returns:
            VeoVideoResult
        """
        start_time = time.time()

        if output_path is None:
            timestamp = int(time.time())
            output_path = str(self.output_dir / f"veo_{timestamp}.mp4")

        self._wait_for_rate_limit()

        try:
            logger.info(f"Generating video from prompt: {prompt[:100]}...")

            # Veo 3.1 Text-to-Video APIï¼ˆéåŒæœŸæ“ä½œï¼‰
            operation = self.client.models.generate_video(
                model=self.model,
                prompt=prompt,
                config=types.GenerateVideoConfig(
                    aspect_ratio=aspect_ratio,
                ),
            )

            logger.info("Waiting for video generation to complete...")

            # æ“ä½œã®å®Œäº†ã‚’å¾…æ©Ÿ
            while not operation.done:
                logger.debug("Still processing...")
                time.sleep(10)
                operation = self.client.operations.get(operation)

            if operation.error:
                raise ValueError(f"Generation failed: {operation.error}")

            response = operation.response

            # å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            video_data = None
            if hasattr(response, 'generated_videos') and response.generated_videos:
                video = response.generated_videos[0]
                if hasattr(video, 'video'):
                    video_data = video.video
                elif hasattr(video, 'video_bytes'):
                    video_data = video.video_bytes

            if not video_data:
                if hasattr(response, 'video'):
                    video_data = response.video

            if not video_data:
                return VeoVideoResult(
                    success=False,
                    error_message="No video generated",
                    generation_time=time.time() - start_time,
                )

            # å‹•ç”»ã‚’ä¿å­˜
            Path(output_path).parent.mkdir(parents=True, exist_ok=True)

            if isinstance(video_data, bytes):
                with open(output_path, "wb") as f:
                    f.write(video_data)
            else:
                import base64
                with open(output_path, "wb") as f:
                    f.write(base64.b64decode(video_data))

            generation_time = time.time() - start_time
            logger.info(f"Video saved: {output_path} ({generation_time:.1f}s)")

            return VeoVideoResult(
                success=True,
                output_path=output_path,
                duration=duration,
                generation_time=generation_time,
            )

        except Exception as e:
            logger.error(f"Video generation failed: {e}")
            return VeoVideoResult(
                success=False,
                error_message=str(e),
                generation_time=time.time() - start_time,
            )

    def create_dynamic_prompt(
        self,
        news_category: str,
        scene_type: str = "intro",
        news_title: str = "",
        additional_context: str = "",
    ) -> str:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚«ãƒ†ã‚´ãƒªã«å¿œã˜ãŸè¶…ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ç”Ÿæˆ

        Args:
            news_category: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚«ãƒ†ã‚´ãƒª
            scene_type: ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ï¼ˆintro, detail, outroï¼‰
            news_title: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ï¼ˆè¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆç”¨ï¼‰
            additional_context: ãã®ä»–ã®è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            å‹•ç”»ç”Ÿæˆç”¨ã®è¶…ãƒ€ã‚¤ãƒŠãƒŸãƒƒã‚¯ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        """
        import random

        # ã‚«ãƒ†ã‚´ãƒªã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        category_prompts = self.MOVEMENT_PROMPTS.get(
            news_category, self.MOVEMENT_PROMPTS["default"]
        )

        # ã‚·ãƒ¼ãƒ³ã‚¿ã‚¤ãƒ—ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å–å¾—
        base_prompt = category_prompts.get(scene_type, category_prompts["intro"])

        # ãƒ©ãƒ³ãƒ€ãƒ ãªå‹•çš„è¦ç´ ã‚’3-4å€‹é¸æŠ
        num_elements = random.randint(3, 4)
        selected_elements = random.sample(self.DYNAMIC_ELEMENTS, num_elements)
        dynamic_suffix = ", ".join(selected_elements)

        # å“è³ªã‚¿ã‚°
        quality_tags = (
            "high production value, broadcast quality, photorealistic rendering, "
            "8K cinematic quality, professional videography, seamless motion"
        )

        # æœ€çµ‚ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        final_prompt = f"{base_prompt}. {dynamic_suffix}. {quality_tags}"

        # è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚Œã°è¿½åŠ 
        if additional_context:
            final_prompt = f"{final_prompt}. {additional_context}"

        logger.info(f"Generated dynamic prompt for [{news_category}/{scene_type}]")
        logger.debug(f"Full prompt: {final_prompt}")

        return final_prompt

    def detect_category(self, title: str) -> str:
        """ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªã‚’åˆ¤å®š

        Args:
            title: ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¿ã‚¤ãƒˆãƒ«

        Returns:
            ã‚«ãƒ†ã‚´ãƒªå
        """
        category_keywords = {
            "æ”¿æ²»": ["æ”¿æ²»", "é¸æŒ™", "å›½ä¼š", "é¦–ç›¸", "æ”¿åºœ", "æ³•æ¡ˆ", "ä¸å…š", "é‡å…š"],
            "çµŒæ¸ˆ": ["çµŒæ¸ˆ", "æ ª", "å††", "ä¼æ¥­", "å¸‚å ´", "é‡‘è", "æŠ•è³‡", "æ™¯æ°—"],
            "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼": ["AI", "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼", "IT", "ãƒ‡ã‚¸ã‚¿ãƒ«", "ãƒ­ãƒœãƒƒãƒˆ", "æŠ€è¡“", "é–‹ç™º"],
            "å›½éš›": ["å›½éš›", "ä¸–ç•Œ", "æµ·å¤–", "å¤–äº¤", "ç±³å›½", "ä¸­å›½", "EU"],
            "ç§‘å­¦": ["ç§‘å­¦", "ç ”ç©¶", "ç™ºè¦‹", "å®‡å®™", "åŒ»ç™‚", "å®Ÿé¨“"],
            "ã‚¹ãƒãƒ¼ãƒ„": ["ã‚¹ãƒãƒ¼ãƒ„", "äº”è¼ª", "ã‚µãƒƒã‚«ãƒ¼", "é‡çƒ", "å„ªå‹", "è©¦åˆ"],
        }

        for category, keywords in category_keywords.items():
            if any(kw in title for kw in keywords):
                return category

        return "default"


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    try:
        generator = VeoVideoGenerator()
        print("VeoVideoGenerator initialized successfully")

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚¹ãƒˆ
        test_title = "AIæŠ€è¡“ãŒå¤‰ãˆã‚‹æœªæ¥ã®åƒãæ–¹"
        category = generator.detect_category(test_title)
        print(f"Category: {category}")

        prompt = generator.create_dynamic_prompt(category, "intro")
        print(f"Prompt: {prompt}")

    except Exception as e:
        print(f"Error: {e}")
